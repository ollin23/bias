{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "591a3db7",
   "metadata": {},
   "source": [
    "# COMPAS MLP FTU - mk2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822aba1b",
   "metadata": {},
   "source": [
    "## Load Dependencies <a id=\"libraries\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0acb8b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import timeit\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "321c01a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882d8f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f073f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c5f98",
   "metadata": {},
   "source": [
    "### Notebook options and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ceb224",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 250\n",
    "pd.options.display.max_rows = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f12b2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed for consistency in pytorch and numpy\n",
    "SEED = 23\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6076047e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24203bde",
   "metadata": {},
   "source": [
    "### Hyperparameter options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86559bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation functions\n",
    "elu = nn.ELU()\n",
    "leaky = nn.LeakyReLU()\n",
    "relu = nn.ReLU()\n",
    "tanh = nn.Tanh()\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "# loss functions\n",
    "mse = nn.MSELoss()\n",
    "bce = nn.BCELoss()\n",
    "kld = nn.KLDivLoss()\n",
    "\n",
    "# optimizers\n",
    "adam = torch.optim.Adam\n",
    "sgd = torch.optim.SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab62d8ef",
   "metadata": {},
   "source": [
    "## Custom Functions <a id=\"functions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba63d8d9",
   "metadata": {},
   "source": [
    "#### Create dataset for DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc43af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.X = torch.tensor(data, dtype=torch.float32, device=device)\n",
    "        self.y = torch.tensor(target, dtype=torch.float32, device=device)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20bf5a2",
   "metadata": {},
   "source": [
    "#### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dd403fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, model, criterion, metric, optimizer):\n",
    "    size = len(data.dataset)\n",
    "    batches = len(data)\n",
    "    running_loss = []\n",
    "    acc = 0.0\n",
    "    correct = 0\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    loss = 0.0\n",
    "    acc = 0.0\n",
    "    current = 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(data,1):\n",
    "        \n",
    "        # forward step\n",
    "        optimizer.zero_grad() # zero out the gradients\n",
    "        y_hat = model(X)  #forward pass\n",
    "        \n",
    "        y = y.unsqueeze(-1) # reduce dimensions of tensor from [256, 1] to [256]\n",
    "        \n",
    "        loss = criterion(y_hat, y)  # calculate loss\n",
    "       \n",
    "        #  backprop step\n",
    "        loss.backward()       # backward pass through model; computes gradients\n",
    "        optimizer.step()      # update weights\n",
    "        \n",
    "        # metrics\n",
    "        y = y.int()\n",
    "        acc = metric(y_hat, y)\n",
    "\n",
    "        y_hat = y_hat.cpu().detach().numpy()\n",
    "        y_hat = y_hat.reshape(-1)\n",
    "        \n",
    "        y = y.cpu().detach().numpy()\n",
    "        y = y.reshape(-1)\n",
    "        \n",
    "        predictions.append(y_hat)\n",
    "        actuals.append(y)\n",
    "            \n",
    "        running_loss.append(loss.item())\n",
    "    \n",
    "        ## every 50 batches, store the results\n",
    "        #if batch % 50 == 0:\n",
    "        #    current = batch * len(X)\n",
    "        \n",
    "    print(f\"\\tTraining\\tAccuracy: {acc:1.10f}\\tLoss: {loss:1.10f}\")\n",
    "    \n",
    "    return predictions, running_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5273a4",
   "metadata": {},
   "source": [
    "#### Testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d07dbf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data, model, criterion, metric):\n",
    "    size = len(data.dataset)\n",
    "    batches = len(data)\n",
    "    tst_loss = 0\n",
    "    correct = 0\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in data:\n",
    "            y_hat = model(X)\n",
    "            y = y.unsqueeze(-1)\n",
    "            tst_loss += criterion(y_hat, y).item()\n",
    "            \n",
    "            y = y.int()\n",
    "            acc = metric(y_hat, y)\n",
    "            #acc = acc.cpu().detach().numpy()\n",
    "            \n",
    "            y_hat = y_hat.cpu().detach().numpy()\n",
    "            y_hat = y_hat.reshape(-1)\n",
    "        \n",
    "            y = y.cpu().detach().numpy()\n",
    "            y = y.reshape(-1)\n",
    "        \n",
    "            predictions.append(y_hat)\n",
    "            actuals.append(y)\n",
    "            \n",
    "    tst_loss /= batches\n",
    "    correct /= size\n",
    "    \n",
    "    print(f\"\\tTest error\\tAccuracy: {acc:1.10f}\\tLoss: {tst_loss:1.10f}\")\n",
    "    return predictions, tst_loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a12ad3",
   "metadata": {},
   "source": [
    "#### Evaluation - train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb53457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(training_data, test_data, model, loss_function, metric, optimizer, epochs, early_stop=True):\n",
    "    training_results = []\n",
    "    training_actuals = []\n",
    "    training_losses = []\n",
    "\n",
    "    testing_results = []\n",
    "    testing_actuals = []\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    # early stop criteria\n",
    "    \n",
    "    default_patience = 3\n",
    "    patience = default_patience\n",
    "    running_loss = []\n",
    "    running_acc = []\n",
    "\n",
    "    for epoch in range(1,epochs+1):\n",
    "        print (f\"Epoch {epoch} / {epochs}\")\n",
    "\n",
    "        trng_result, trng_loss = train(training_data, model, loss_function, metric, optimizer)\n",
    "        tst_result, tst_loss, acc = test(test_data, model, loss_function, metric)\n",
    "        \n",
    "        training_results.append(trng_result)\n",
    "        training_losses.append(trng_loss)\n",
    "        testing_results.append(tst_result)\n",
    "        running_loss.append(tst_loss)\n",
    "        running_acc.append(acc)\n",
    "        \n",
    "        # check for early stop\n",
    "        if epoch > 3:            \n",
    "            if early_stop and ((tst_loss >= running_loss[-2]) or math.isclose(acc,running_acc[-2], abs_tol=1e-8)):\n",
    "                patience = patience - 1\n",
    "            elif early_stop and (tst_loss < running_loss[-2]):\n",
    "                patience = default_patience\n",
    "\n",
    "            if early_stop and (patience <= 0):\n",
    "                print(\"Early stop - \", end=\"\")\n",
    "                break\n",
    "\n",
    "    \n",
    "    print(\"Finished\")\n",
    "    print(\"* \" * 30)\n",
    "    stop = timeit.default_timer()\n",
    "    print(f\"Execution time (in seconds): {stop - start}\")\n",
    "\n",
    "    return training_results, training_losses, testing_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee9a693",
   "metadata": {},
   "source": [
    "#### Multilayer Perception (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd866587",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_size, hidden1=relu, hidden2=relu, hidden3=relu, out_layer=sigmoid):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # construct model dependent on size of inputs\n",
    "        out1_2 = 2*in_size // 3\n",
    "        out2_3 = 2*out1_2 // 3\n",
    "        out3_4 = 2*out2_3 // 3\n",
    "\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(in_size, out1_2),\n",
    "            hidden1,\n",
    "            nn.Linear(out1_2, out2_3),\n",
    "            hidden2,\n",
    "            nn.Linear(out2_3, out3_4),\n",
    "            hidden3,\n",
    "            nn.Linear(out3_4, 1),\n",
    "            out_layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear_stack(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5050abe0",
   "metadata": {},
   "source": [
    "#### Flatten function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "954283c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(thing):\n",
    "    '''\n",
    "    thing: a list\n",
    "    \n",
    "    flatten receives a multi-level list and flatten it down 2 layers\n",
    "    '''\n",
    "    #thing = [element for sublist in thing for element in sublist]\n",
    "    return [element for sublist in thing for element in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fa944e",
   "metadata": {},
   "source": [
    "#### Prepare data for eval and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e211064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(name, training_results, testing_results):\n",
    "    trng_preds = [[] for _ in range(len(training_results))]\n",
    "\n",
    "    tst_preds = [[] for _ in range(len(testing_results))]\n",
    "    \n",
    "    for i in range(len(training_results)):\n",
    "        trng_preds[i] = flatten(training_results[i])\n",
    "\n",
    "        tst_preds[i] = flatten(testing_results[i])\n",
    "\n",
    "    return trng_preds, tst_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1c9839",
   "metadata": {},
   "source": [
    "#### Send results to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a30567c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensorboard(tailend, directory, dataset, train_preds, test_preds, y_train, y_test):\n",
    "    acc_trng_relu = []\n",
    "    acc_tst_relu = []\n",
    "    loss_relu = []\n",
    "\n",
    "    writer = SummaryWriter(log_dir=directory)\n",
    "\n",
    "    for i in range(len(train_preds)):\n",
    "        y_hat = np.array(np.round(train_preds[i]))\n",
    "        y_hat_tst = np.array(np.round(test_preds[i]))\n",
    "        trng_acc = (y_hat == y_train).sum()/len(train_preds[i])\n",
    "        test_acc = (y_hat_tst == y_test).sum()/len(test_preds[i])\n",
    "\n",
    "        avg_loss = np.average(training_losses[i])\n",
    "\n",
    "        acc_trng_relu.append(trng_acc)\n",
    "        acc_tst_relu.append(test_acc)\n",
    "        loss_relu.append(avg_loss)\n",
    "        writer.add_scalar(f\"Training Accuracy {tailend}\", trng_acc, i)\n",
    "        writer.add_scalar(f\"Test Accuracy {tailend}\", test_acc, i)\n",
    "        writer.add_scalar(f\"Training Loss {tailend}\", avg_loss, i)\n",
    "        writer.add_pr_curve(f\"Precision-Recall Curve {tailend}\", y_test, y_hat_tst, i)\n",
    "\n",
    "    t, _ = next(iter(dataset))\n",
    "    writer.add_graph(model, t)\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eef51f5",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10504309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_save(name, data, kind=1):\n",
    "    '''\n",
    "    name : string\n",
    "        designated filename\n",
    "    data : data or pytorch model\n",
    "        the data to save\n",
    "    kind : int\n",
    "        sentinel value - 1 if pytorch model, 0 otherwise\n",
    "    \n",
    "    custom_save stores the data passed into the function into a file with the provided name\n",
    "    '''\n",
    "    \n",
    "    if kind == 1:\n",
    "        ex = \".pth\"\n",
    "    else:\n",
    "        ex = \".parquet\"\n",
    "    \n",
    "    sentinel = True\n",
    "    i = 1\n",
    "\n",
    "    while sentinel:\n",
    "        dirlist = os.listdir()\n",
    "\n",
    "        if name not in dirlist:\n",
    "            if kind == 1:\n",
    "                torch.save(data, name)\n",
    "            else:\n",
    "                data.to_parquet(name)\n",
    "            print(f\"{name} has been saved.\")                \n",
    "            sentinel = False\n",
    "        if name in dirlist:\n",
    "            print(f\"{name} already exists.\", end=\" \")\n",
    "            temp, ext = name.split(ex)\n",
    "            if \"_v\" in temp:\n",
    "                temp, _ = temp.split(\"_v\")\n",
    "            name = f\"{temp}_v{i}{ex}\"\n",
    "            i = i + 1\n",
    "            print(f\"Changing file name to: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8543ae",
   "metadata": {},
   "source": [
    "# Import Data<a id=\"data\"></a>\n",
    "##### COMPAS dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84f4f8b",
   "metadata": {},
   "source": [
    "#### Uncomment next when using google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4288012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_parquet(\"https://github.com/ollin23/bias/blob/main/compas_mk1_v1.parquet?raw=true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5382982d",
   "metadata": {},
   "source": [
    "#### Use the following cell if the data is stored locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "954ed19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(\"compas_mk1_v1.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8795f35",
   "metadata": {},
   "source": [
    "#### Peak the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab028d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6907 entries, 0 to 7213\n",
      "Data columns (total 34 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   age                      6907 non-null   int64  \n",
      " 1   juv_fel_count            6907 non-null   int64  \n",
      " 2   decile_score             6907 non-null   int64  \n",
      " 3   juv_misd_count           6907 non-null   int64  \n",
      " 4   juv_other_count          6907 non-null   int64  \n",
      " 5   priors_count             6907 non-null   int64  \n",
      " 6   days_b_screening_arrest  6907 non-null   float64\n",
      " 7   c_days_from_compas       6907 non-null   float64\n",
      " 8   is_recid                 6907 non-null   int64  \n",
      " 9   is_violent_recid         6907 non-null   int64  \n",
      " 10  decile_score.1           6907 non-null   int64  \n",
      " 11  v_decile_score           6907 non-null   int64  \n",
      " 12  priors_count.1           6907 non-null   int64  \n",
      " 13  start                    6907 non-null   int64  \n",
      " 14  end                      6907 non-null   int64  \n",
      " 15  sex                      6907 non-null   uint8  \n",
      " 16  age_cat_25to45           6907 non-null   uint8  \n",
      " 17  age_cat_over45           6907 non-null   uint8  \n",
      " 18  age_cat_under25          6907 non-null   uint8  \n",
      " 19  race_black               6907 non-null   uint8  \n",
      " 20  race_asian               6907 non-null   uint8  \n",
      " 21  race_white               6907 non-null   uint8  \n",
      " 22  race_hispanic            6907 non-null   uint8  \n",
      " 23  race_native              6907 non-null   uint8  \n",
      " 24  race_Other               6907 non-null   uint8  \n",
      " 25  c_charge_degree          6907 non-null   uint8  \n",
      " 26  score_text_High          6907 non-null   uint8  \n",
      " 27  score_text_Low           6907 non-null   uint8  \n",
      " 28  score_text_Medium        6907 non-null   uint8  \n",
      " 29  v_score_text_High        6907 non-null   uint8  \n",
      " 30  v_score_text_Low         6907 non-null   uint8  \n",
      " 31  v_score_text_Medium      6907 non-null   uint8  \n",
      " 32  event                    6907 non-null   int64  \n",
      " 33  target                   6907 non-null   int64  \n",
      "dtypes: float64(2), int64(15), uint8(17)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a10d91bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6907, 34)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17166be3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat_25to45</th>\n",
       "      <th>age_cat_over45</th>\n",
       "      <th>age_cat_under25</th>\n",
       "      <th>race_black</th>\n",
       "      <th>race_asian</th>\n",
       "      <th>race_white</th>\n",
       "      <th>race_hispanic</th>\n",
       "      <th>race_native</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>score_text_High</th>\n",
       "      <th>score_text_Low</th>\n",
       "      <th>score_text_Medium</th>\n",
       "      <th>v_score_text_High</th>\n",
       "      <th>v_score_text_Low</th>\n",
       "      <th>v_score_text_Medium</th>\n",
       "      <th>event</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>853</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  juv_fel_count  decile_score  juv_misd_count  juv_other_count  \\\n",
       "0   69              0             1               0                0   \n",
       "1   34              0             3               0                0   \n",
       "2   24              0             4               0                1   \n",
       "5   44              0             1               0                0   \n",
       "6   41              0             6               0                0   \n",
       "\n",
       "   priors_count  days_b_screening_arrest  c_days_from_compas  is_recid  \\\n",
       "0             0                     -1.0                 1.0         0   \n",
       "1             0                     -1.0                 1.0         1   \n",
       "2             4                     -1.0                 1.0         1   \n",
       "5             0                      0.0                 0.0         0   \n",
       "6            14                     -1.0                 1.0         1   \n",
       "\n",
       "   is_violent_recid  decile_score.1  v_decile_score  priors_count.1  start  \\\n",
       "0                 0               1               1               0      0   \n",
       "1                 1               3               1               0      9   \n",
       "2                 0               4               3               4      0   \n",
       "5                 0               1               1               0      1   \n",
       "6                 0               6               2              14      5   \n",
       "\n",
       "   end  sex  age_cat_25to45  age_cat_over45  age_cat_under25  race_black  \\\n",
       "0  327    0               0               1                0           0   \n",
       "1  159    0               1               0                0           1   \n",
       "2   63    0               0               0                1           1   \n",
       "5  853    0               1               0                0           0   \n",
       "6   40    0               1               0                0           0   \n",
       "\n",
       "   race_asian  race_white  race_hispanic  race_native  race_Other  \\\n",
       "0           0           0              0            0           1   \n",
       "1           0           0              0            0           0   \n",
       "2           0           0              0            0           0   \n",
       "5           0           0              0            0           1   \n",
       "6           0           1              0            0           0   \n",
       "\n",
       "   c_charge_degree  score_text_High  score_text_Low  score_text_Medium  \\\n",
       "0                1                0               1                  0   \n",
       "1                1                0               1                  0   \n",
       "2                1                0               1                  0   \n",
       "5                0                0               1                  0   \n",
       "6                1                0               0                  1   \n",
       "\n",
       "   v_score_text_High  v_score_text_Low  v_score_text_Medium  event  target  \n",
       "0                  0                 1                    0      0       0  \n",
       "1                  0                 1                    0      1       1  \n",
       "2                  0                 1                    0      0       1  \n",
       "5                  0                 1                    0      0       0  \n",
       "6                  0                 1                    0      1       1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a50e7fb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'juv_fel_count',\n",
       " 'decile_score',\n",
       " 'juv_misd_count',\n",
       " 'juv_other_count',\n",
       " 'priors_count',\n",
       " 'days_b_screening_arrest',\n",
       " 'c_days_from_compas',\n",
       " 'is_recid',\n",
       " 'is_violent_recid',\n",
       " 'decile_score.1',\n",
       " 'v_decile_score',\n",
       " 'priors_count.1',\n",
       " 'start',\n",
       " 'end',\n",
       " 'sex',\n",
       " 'age_cat_25to45',\n",
       " 'age_cat_over45',\n",
       " 'age_cat_under25',\n",
       " 'race_black',\n",
       " 'race_asian',\n",
       " 'race_white',\n",
       " 'race_hispanic',\n",
       " 'race_native',\n",
       " 'race_Other',\n",
       " 'c_charge_degree',\n",
       " 'score_text_High',\n",
       " 'score_text_Low',\n",
       " 'score_text_Medium',\n",
       " 'v_score_text_High',\n",
       " 'v_score_text_Low',\n",
       " 'v_score_text_Medium',\n",
       " 'event',\n",
       " 'target']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6c264c",
   "metadata": {},
   "source": [
    "### Process Data for Neural Net Usage <a id=\"convert\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc92a8e3",
   "metadata": {},
   "source": [
    "#### Split features into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "574fe802",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"target\", axis=1).values.astype(np.float32)\n",
    "y = data.target.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6bf1c7",
   "metadata": {},
   "source": [
    "#### Standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a94a72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaledX = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a40e89",
   "metadata": {},
   "source": [
    "#### Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b312d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaledX, y, test_size=0.3,\n",
    "                                                        random_state=SEED, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53ed4dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4834, 33)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d0aac4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2073, 33)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f186d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = list(data.columns).index(\"race_black\")\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "248f973d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['race_black', 'race_asian', 'race_white', 'race_hispanic',\n",
       "       'race_native', 'race_Other'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[19:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8f97e9",
   "metadata": {},
   "source": [
    "black = X_test[:, 19]\n",
    "asian = X_test[:, 20]\n",
    "white = X_test[:, 21]\n",
    "hispanic = X_test[:, 22]\n",
    "native = X_test[:, 23]\n",
    "other = X_test[:,24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af33bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.round(scaler.inverse_transform(X_test)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35f25c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.delete(X_train, [19,20,21,22,23,24], axis=1)\n",
    "X_test = np.delete(X_test, [19,20,21,22,23,24], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef745fd",
   "metadata": {},
   "source": [
    "#### Make datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "040aab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train = dataset(X_train, y_train)\n",
    "scaled_test = dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860c0e3",
   "metadata": {},
   "source": [
    "##### Construct test results dataframe for persistent storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "190a7d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(data.drop(\"target\", axis=1).columns)\n",
    "\n",
    "df = pd.DataFrame(temp, columns=features)\n",
    "black = df.race_black.values\n",
    "white = df.race_white.values\n",
    "hispanic = df.race_hispanic.values\n",
    "native = df.race_native.values\n",
    "other = df.race_Other.values\n",
    "\n",
    "# drop old \n",
    "df.drop([\"race_black\", \"race_white\", \"race_hispanic\", \"race_native\", \\\n",
    "         \"race_Other\"], axis=1, inplace=True)\n",
    "\n",
    "df[\"black\"] = black\n",
    "df[\"white\"] = white\n",
    "df[\"hispanic\"] = hispanic\n",
    "df[\"native\"] = native\n",
    "df[\"other\"] = other\n",
    "df[\"target\"] = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1cacf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat_25to45</th>\n",
       "      <th>age_cat_over45</th>\n",
       "      <th>age_cat_under25</th>\n",
       "      <th>race_asian</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>score_text_High</th>\n",
       "      <th>score_text_Low</th>\n",
       "      <th>score_text_Medium</th>\n",
       "      <th>v_score_text_High</th>\n",
       "      <th>v_score_text_Low</th>\n",
       "      <th>v_score_text_Medium</th>\n",
       "      <th>event</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>native</th>\n",
       "      <th>other</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1171</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  juv_fel_count  decile_score  juv_misd_count  juv_other_count  \\\n",
       "0   25              0             5               0                1   \n",
       "1   35              0             4               0                0   \n",
       "2   32              0             4               0                0   \n",
       "3   20              0            10               0                0   \n",
       "4   50              0             8               0                2   \n",
       "\n",
       "   priors_count  days_b_screening_arrest  c_days_from_compas  is_recid  \\\n",
       "0             4                       -1                   1         1   \n",
       "1             3                       -1                   0         1   \n",
       "2             1                        0                   0         0   \n",
       "3             0                       -1                   1         1   \n",
       "4            24                        0                   1         1   \n",
       "\n",
       "   is_violent_recid  decile_score.1  v_decile_score  priors_count.1  start  \\\n",
       "0                 0               5               4               4     32   \n",
       "1                 0               4               4               3      9   \n",
       "2                 0               4               3               1      0   \n",
       "3                 1              10              10               0      3   \n",
       "4                 1               8               8              24     32   \n",
       "\n",
       "    end  sex  age_cat_25to45  age_cat_over45  age_cat_under25  race_asian  \\\n",
       "0   304    0               1               0                0           0   \n",
       "1   462    0               1               0                0           0   \n",
       "2  1171    0               1               0                0           0   \n",
       "3    20    0               0               0                1           0   \n",
       "4    87    0               0               1                0           0   \n",
       "\n",
       "   c_charge_degree  score_text_High  score_text_Low  score_text_Medium  \\\n",
       "0                1                0               0                  1   \n",
       "1                0                0               1                  0   \n",
       "2                1                0               1                  0   \n",
       "3                0                1               0                  0   \n",
       "4                0                1               0                  0   \n",
       "\n",
       "   v_score_text_High  v_score_text_Low  v_score_text_Medium  event  black  \\\n",
       "0                  0                 1                    0      1      1   \n",
       "1                  0                 1                    0      1      0   \n",
       "2                  0                 1                    0      0      1   \n",
       "3                  1                 0                    0      1      1   \n",
       "4                  1                 0                    0      0      1   \n",
       "\n",
       "   white  hispanic  native  other  target  \n",
       "0      0         0       0      0       1  \n",
       "1      1         0       0      0       1  \n",
       "2      0         0       0      0       0  \n",
       "3      0         0       0      0       1  \n",
       "4      0         0       0      0       1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23430d6b",
   "metadata": {},
   "source": [
    "##### Note\n",
    "For this dataset: Female == 1, Male == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28549706",
   "metadata": {},
   "source": [
    "# Experiment Phase 3 - COMPAS Data <a id=\"experiments\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b7fe77",
   "metadata": {},
   "source": [
    "## Trial 3.1 - ReLU (COMPAS) <a id=\"relu\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefc8941",
   "metadata": {},
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af9d93ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"mk2_FTU\"\n",
    "directory = f\"COMPAS_{suffix}\"\n",
    "prefix = \"compas\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d3c26",
   "metadata": {},
   "source": [
    "#### Hyperparameters <a id=\"hyperparameters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7aede70",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-5 # 0.00001\n",
    "epochs = 150\n",
    "batches = 100\n",
    "hidden1 = relu\n",
    "hidden2 = relu\n",
    "hidden3 = relu\n",
    "out_layer = sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94eb85f",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68dd22dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to feed data into pytorch neural network, only needs to execute once\n",
    "training_s = DataLoader(scaled_train, batch_size=batches)\n",
    "test_s = DataLoader(scaled_test, batch_size=batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cacc105",
   "metadata": {},
   "source": [
    "#### Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db4bf9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of MLP(\n",
      "  (linear_stack): Sequential(\n",
      "    (0): Linear(in_features=27, out_features=18, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=18, out_features=12, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=12, out_features=8, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=8, out_features=1, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# instantiate model\n",
    "model = MLP(X_train.shape[1], hidden1, hidden2, hidden3, out_layer).to(device)\n",
    "\n",
    "# select optimizing function\n",
    "optimizer = adam(model.parameters(), lr=alpha)\n",
    "\n",
    "# select loss function\n",
    "loss_function = mse\n",
    "\n",
    "# accuracy metric\n",
    "metric = torchmetrics.functional.accuracy\n",
    "\n",
    "# display model\n",
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dda5258",
   "metadata": {},
   "source": [
    "#### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b3becb2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2482961714\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2482213264\n",
      "Epoch 2 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2479248643\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2478888127\n",
      "Epoch 3 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2475468665\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2475545201\n",
      "Epoch 4 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2471761107\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2472212733\n",
      "Epoch 5 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2467991859\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2468845489\n",
      "Epoch 6 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2464226633\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2465480445\n",
      "Epoch 7 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2460504472\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2462079475\n",
      "Epoch 8 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2456572801\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2458682600\n",
      "Epoch 9 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2452515960\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2455230689\n",
      "Epoch 10 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2448397577\n",
      "\tTest error\tAccuracy: 0.5890411139\tLoss: 0.2451769319\n",
      "Epoch 11 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2444259375\n",
      "\tTest error\tAccuracy: 0.5890411139\tLoss: 0.2448278091\n",
      "Epoch 12 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2440079004\n",
      "\tTest error\tAccuracy: 0.5890411139\tLoss: 0.2444719949\n",
      "Epoch 13 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2435869873\n",
      "\tTest error\tAccuracy: 0.5890411139\tLoss: 0.2441111179\n",
      "Epoch 14 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2431675643\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2437502536\n",
      "Epoch 15 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2427284867\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2433887131\n",
      "Epoch 16 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2422874719\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2430200492\n",
      "Epoch 17 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2418333441\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2426472037\n",
      "Epoch 18 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2413833886\n",
      "\tTest error\tAccuracy: 0.6301369667\tLoss: 0.2422698062\n",
      "Epoch 19 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2409517616\n",
      "\tTest error\tAccuracy: 0.6301369667\tLoss: 0.2418886338\n",
      "Epoch 20 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2405013144\n",
      "\tTest error\tAccuracy: 0.6301369667\tLoss: 0.2415101322\n",
      "Epoch 21 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2400419861\n",
      "\tTest error\tAccuracy: 0.6301369667\tLoss: 0.2411168459\n",
      "Epoch 22 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2395896912\n",
      "\tTest error\tAccuracy: 0.6301369667\tLoss: 0.2407262581\n",
      "Epoch 23 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2391344011\n",
      "\tTest error\tAccuracy: 0.6438356042\tLoss: 0.2403306173\n",
      "Epoch 24 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2386755645\n",
      "\tTest error\tAccuracy: 0.6575342417\tLoss: 0.2399290963\n",
      "Epoch 25 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2382050753\n",
      "\tTest error\tAccuracy: 0.6712328792\tLoss: 0.2395174290\n",
      "Epoch 26 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2377061248\n",
      "\tTest error\tAccuracy: 0.6712328792\tLoss: 0.2390951174\n",
      "Epoch 27 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2371986061\n",
      "\tTest error\tAccuracy: 0.6712328792\tLoss: 0.2386703740\n",
      "Epoch 28 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2366851419\n",
      "\tTest error\tAccuracy: 0.6712328792\tLoss: 0.2382381097\n",
      "Epoch 29 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2361658961\n",
      "\tTest error\tAccuracy: 0.6712328792\tLoss: 0.2377959298\n",
      "Epoch 30 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2356486619\n",
      "\tTest error\tAccuracy: 0.6712328792\tLoss: 0.2373490412\n",
      "Epoch 31 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2351148874\n",
      "\tTest error\tAccuracy: 0.6712328792\tLoss: 0.2368974388\n",
      "Epoch 32 / 150\n",
      "\tTraining\tAccuracy: 0.6176470518\tLoss: 0.2345837206\n",
      "\tTest error\tAccuracy: 0.6849315166\tLoss: 0.2364412120\n",
      "Epoch 33 / 150\n",
      "\tTraining\tAccuracy: 0.6470588446\tLoss: 0.2340426743\n",
      "\tTest error\tAccuracy: 0.6849315166\tLoss: 0.2359755891\n",
      "Epoch 34 / 150\n",
      "\tTraining\tAccuracy: 0.6470588446\tLoss: 0.2335114479\n",
      "\tTest error\tAccuracy: 0.6986301541\tLoss: 0.2355098817\n",
      "Epoch 35 / 150\n",
      "\tTraining\tAccuracy: 0.6470588446\tLoss: 0.2329777181\n",
      "\tTest error\tAccuracy: 0.6986301541\tLoss: 0.2350408073\n",
      "Epoch 36 / 150\n",
      "\tTraining\tAccuracy: 0.6470588446\tLoss: 0.2324398905\n",
      "\tTest error\tAccuracy: 0.6986301541\tLoss: 0.2345661187\n",
      "Epoch 37 / 150\n",
      "\tTraining\tAccuracy: 0.6470588446\tLoss: 0.2319024205\n",
      "\tTest error\tAccuracy: 0.7123287916\tLoss: 0.2340876112\n",
      "Epoch 38 / 150\n",
      "\tTraining\tAccuracy: 0.6470588446\tLoss: 0.2313778996\n",
      "\tTest error\tAccuracy: 0.7123287916\tLoss: 0.2336071701\n",
      "Epoch 39 / 150\n",
      "\tTraining\tAccuracy: 0.6470588446\tLoss: 0.2308444828\n",
      "\tTest error\tAccuracy: 0.7260273695\tLoss: 0.2331185000\n",
      "Epoch 40 / 150\n",
      "\tTraining\tAccuracy: 0.6470588446\tLoss: 0.2303019911\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2326255306\n",
      "Epoch 41 / 150\n",
      "\tTraining\tAccuracy: 0.6470588446\tLoss: 0.2297484726\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2321290984\n",
      "Epoch 42 / 150\n",
      "\tTraining\tAccuracy: 0.6470588446\tLoss: 0.2291764170\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2316279142\n",
      "Epoch 43 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2286176085\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2311297726\n",
      "Epoch 44 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2280343473\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2306078672\n",
      "Epoch 45 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2274523377\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2300903790\n",
      "Epoch 46 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2268570811\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2295612714\n",
      "Epoch 47 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2262607962\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2290256109\n",
      "Epoch 48 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2256530672\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2284823855\n",
      "Epoch 49 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2250390053\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2279330017\n",
      "Epoch 50 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2244115621\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2273767640\n",
      "Epoch 51 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2237862200\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2268074041\n",
      "Epoch 52 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2231664658\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2262417355\n",
      "Epoch 53 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2225245088\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2256645369\n",
      "Epoch 54 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2218648791\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2250795563\n",
      "Epoch 55 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2212195545\n",
      "\tTest error\tAccuracy: 0.7534246445\tLoss: 0.2244998266\n",
      "Epoch 56 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2205452025\n",
      "\tTest error\tAccuracy: 0.7534246445\tLoss: 0.2239090893\n",
      "Epoch 57 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2198698670\n",
      "\tTest error\tAccuracy: 0.7671232820\tLoss: 0.2233171385\n",
      "Epoch 58 / 150\n",
      "\tTraining\tAccuracy: 0.7352941036\tLoss: 0.2191717178\n",
      "\tTest error\tAccuracy: 0.7671232820\tLoss: 0.2227187093\n",
      "Epoch 59 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2184796333\n",
      "\tTest error\tAccuracy: 0.7671232820\tLoss: 0.2221174623\n",
      "Epoch 60 / 150\n",
      "\tTraining\tAccuracy: 0.7352941036\tLoss: 0.2177933604\n",
      "\tTest error\tAccuracy: 0.7671232820\tLoss: 0.2215122524\n",
      "Epoch 61 / 150\n",
      "\tTraining\tAccuracy: 0.7352941036\tLoss: 0.2170949876\n",
      "\tTest error\tAccuracy: 0.7671232820\tLoss: 0.2208940259\n",
      "Epoch 62 / 150\n",
      "\tTraining\tAccuracy: 0.7352941036\tLoss: 0.2164050490\n",
      "\tTest error\tAccuracy: 0.7671232820\tLoss: 0.2202810595\n",
      "Epoch 63 / 150\n",
      "\tTraining\tAccuracy: 0.7352941036\tLoss: 0.2157034278\n",
      "\tTest error\tAccuracy: 0.7671232820\tLoss: 0.2196549496\n",
      "Epoch 64 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2150070369\n",
      "\tTest error\tAccuracy: 0.7671232820\tLoss: 0.2190252401\n",
      "Epoch 65 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2142825723\n",
      "\tTest error\tAccuracy: 0.7808219194\tLoss: 0.2183951210\n",
      "Epoch 66 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2135549784\n",
      "\tTest error\tAccuracy: 0.7945205569\tLoss: 0.2177463167\n",
      "Epoch 67 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2128539383\n",
      "\tTest error\tAccuracy: 0.7945205569\tLoss: 0.2171036977\n",
      "Epoch 68 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2121473700\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.2164504521\n",
      "Epoch 69 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2114368230\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.2157887284\n",
      "Epoch 70 / 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2107095271\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.2151189418\n",
      "Epoch 71 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2099732757\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.2144449524\n",
      "Epoch 72 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2092434317\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.2137653750\n",
      "Epoch 73 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2085102648\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.2130737794\n",
      "Epoch 74 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2077711076\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2123877754\n",
      "Epoch 75 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2070229799\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2116830271\n",
      "Epoch 76 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2062654942\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2109761650\n",
      "Epoch 77 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2054741383\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2102476408\n",
      "Epoch 78 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2047147602\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.2095374302\n",
      "Epoch 79 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2039280236\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2087951466\n",
      "Epoch 80 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2031445205\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.2080628120\n",
      "Epoch 81 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2023327351\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.2073161708\n",
      "Epoch 82 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2015067339\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.2065578380\n",
      "Epoch 83 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2006856650\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2058002069\n",
      "Epoch 84 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1998569816\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2050296246\n",
      "Epoch 85 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1990233809\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2042521650\n",
      "Epoch 86 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1981958002\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2034834219\n",
      "Epoch 87 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1973383278\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2026986544\n",
      "Epoch 88 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1965133101\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2019112053\n",
      "Epoch 89 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1956587732\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2011257332\n",
      "Epoch 90 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1948011369\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2003263157\n",
      "Epoch 91 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1939383745\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1995305533\n",
      "Epoch 92 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1930532157\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1987111143\n",
      "Epoch 93 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1921452433\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1978954900\n",
      "Epoch 94 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1912416071\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1970731382\n",
      "Epoch 95 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1903369725\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1962583257\n",
      "Epoch 96 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1894224137\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1954220682\n",
      "Epoch 97 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1885146797\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1945956087\n",
      "Epoch 98 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1876002997\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1937562667\n",
      "Epoch 99 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1867153645\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1929270114\n",
      "Epoch 100 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1858085543\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1920881747\n",
      "Epoch 101 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1849011630\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1912401205\n",
      "Epoch 102 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1840023696\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1904003017\n",
      "Epoch 103 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1830934286\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1895510334\n",
      "Epoch 104 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1821954399\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1886911882\n",
      "Epoch 105 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1812844276\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1878279128\n",
      "Epoch 106 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1803900748\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1869862002\n",
      "Epoch 107 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1795009524\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1861409857\n",
      "Epoch 108 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1785826087\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1852792792\n",
      "Epoch 109 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1776774675\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1844172251\n",
      "Epoch 110 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1767635643\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1835520438\n",
      "Epoch 111 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1758680493\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1827007241\n",
      "Epoch 112 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1749853492\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1818402495\n",
      "Epoch 113 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1740756780\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1809676957\n",
      "Epoch 114 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1731841266\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1801012655\n",
      "Epoch 115 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1722831428\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1792433964\n",
      "Epoch 116 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1713746339\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1783657251\n",
      "Epoch 117 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1704768836\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1775117126\n",
      "Epoch 118 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1695700884\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1766243314\n",
      "Epoch 119 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1686643213\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1757592566\n",
      "Epoch 120 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1677512079\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1748873102\n",
      "Epoch 121 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1668312699\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1740118379\n",
      "Epoch 122 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1659118980\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1731380693\n",
      "Epoch 123 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1649799496\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1722560901\n",
      "Epoch 124 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1640544236\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1713812827\n",
      "Epoch 125 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1631449759\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1705181130\n",
      "Epoch 126 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1622146666\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1696322440\n",
      "Epoch 127 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1612950414\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1687551829\n",
      "Epoch 128 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1603753269\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1678904252\n",
      "Epoch 129 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1594531685\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1670235112\n",
      "Epoch 130 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1585084945\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1661215105\n",
      "Epoch 131 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1575867981\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1652521981\n",
      "Epoch 132 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1566561311\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1643671471\n",
      "Epoch 133 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1557448655\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1634794410\n",
      "Epoch 134 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1548090279\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1625903029\n",
      "Epoch 135 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1538718194\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1617111251\n",
      "Epoch 136 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1529721171\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1608331778\n",
      "Epoch 137 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1520490348\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1599474649\n",
      "Epoch 138 / 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1511273980\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1590668822\n",
      "Epoch 139 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1502156854\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1581822116\n",
      "Epoch 140 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1492963135\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1572961715\n",
      "Epoch 141 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1483827531\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1564185570\n",
      "Epoch 142 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1474650055\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1555178173\n",
      "Epoch 143 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1465667039\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1546363412\n",
      "Epoch 144 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1456639320\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1537606298\n",
      "Epoch 145 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1447634399\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1528802464\n",
      "Epoch 146 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1438699365\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1519924729\n",
      "Epoch 147 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1429547369\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1511034582\n",
      "Epoch 148 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1420494765\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1502078573\n",
      "Epoch 149 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1411632150\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1493228844\n",
      "Epoch 150 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1402779818\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1484449336\n",
      "Finished\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * \n",
      "Execution time (in seconds): 18.953159090000554\n"
     ]
    }
   ],
   "source": [
    "training_results = []\n",
    "training_losses = []\n",
    "testing_results = []\n",
    "\n",
    "training_results, training_losses, testing_results = evaluate(training_s,\n",
    "                                                            test_s,\n",
    "                                                            model,\n",
    "                                                            loss_function,\n",
    "                                                            metric,\n",
    "                                                            optimizer,\n",
    "                                                            epochs,\n",
    "                                                            early_stop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d74917",
   "metadata": {},
   "source": [
    "### Prepare results for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06e25235",
   "metadata": {},
   "outputs": [],
   "source": [
    "tailend = f\"ReLU ({prefix})\"\n",
    "\n",
    "train_preds, test_preds = prep(tailend, training_results, testing_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad279eb",
   "metadata": {},
   "source": [
    "#### Save ReLU Metrics to Tensorboard <a id=\"relu-metrics-for-tensorboard\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7912815",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensorboard(tailend, directory, training_s, train_preds, test_preds, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efce9ecb",
   "metadata": {},
   "source": [
    "#### Add ReLU predictions to persistent storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4472d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compas_relu_mk2_FTU.pth has been saved.\n"
     ]
    }
   ],
   "source": [
    "df[\"pred_relu\"] = np.array(np.round(test_preds[-1])).astype(int)\n",
    "\n",
    "name = f\"{prefix}_relu_{suffix}.pth\"\n",
    "custom_save(name, model)\n",
    "#torch.save(model, f\"{prefix}_relu_scaled.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a2db524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat_25to45</th>\n",
       "      <th>age_cat_over45</th>\n",
       "      <th>age_cat_under25</th>\n",
       "      <th>race_asian</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>score_text_High</th>\n",
       "      <th>score_text_Low</th>\n",
       "      <th>score_text_Medium</th>\n",
       "      <th>v_score_text_High</th>\n",
       "      <th>v_score_text_Low</th>\n",
       "      <th>v_score_text_Medium</th>\n",
       "      <th>event</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>native</th>\n",
       "      <th>other</th>\n",
       "      <th>target</th>\n",
       "      <th>pred_relu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1171</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  juv_fel_count  decile_score  juv_misd_count  juv_other_count  \\\n",
       "0   25              0             5               0                1   \n",
       "1   35              0             4               0                0   \n",
       "2   32              0             4               0                0   \n",
       "3   20              0            10               0                0   \n",
       "4   50              0             8               0                2   \n",
       "\n",
       "   priors_count  days_b_screening_arrest  c_days_from_compas  is_recid  \\\n",
       "0             4                       -1                   1         1   \n",
       "1             3                       -1                   0         1   \n",
       "2             1                        0                   0         0   \n",
       "3             0                       -1                   1         1   \n",
       "4            24                        0                   1         1   \n",
       "\n",
       "   is_violent_recid  decile_score.1  v_decile_score  priors_count.1  start  \\\n",
       "0                 0               5               4               4     32   \n",
       "1                 0               4               4               3      9   \n",
       "2                 0               4               3               1      0   \n",
       "3                 1              10              10               0      3   \n",
       "4                 1               8               8              24     32   \n",
       "\n",
       "    end  sex  age_cat_25to45  age_cat_over45  age_cat_under25  race_asian  \\\n",
       "0   304    0               1               0                0           0   \n",
       "1   462    0               1               0                0           0   \n",
       "2  1171    0               1               0                0           0   \n",
       "3    20    0               0               0                1           0   \n",
       "4    87    0               0               1                0           0   \n",
       "\n",
       "   c_charge_degree  score_text_High  score_text_Low  score_text_Medium  \\\n",
       "0                1                0               0                  1   \n",
       "1                0                0               1                  0   \n",
       "2                1                0               1                  0   \n",
       "3                0                1               0                  0   \n",
       "4                0                1               0                  0   \n",
       "\n",
       "   v_score_text_High  v_score_text_Low  v_score_text_Medium  event  black  \\\n",
       "0                  0                 1                    0      1      1   \n",
       "1                  0                 1                    0      1      0   \n",
       "2                  0                 1                    0      0      1   \n",
       "3                  1                 0                    0      1      1   \n",
       "4                  1                 0                    0      0      1   \n",
       "\n",
       "   white  hispanic  native  other  target  pred_relu  \n",
       "0      0         0       0      0       1          1  \n",
       "1      1         0       0      0       1          1  \n",
       "2      0         0       0      0       0          0  \n",
       "3      0         0       0      0       1          1  \n",
       "4      0         0       0      0       1          1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811f57a4",
   "metadata": {},
   "source": [
    "## Trial 3.2 - Tanh (COMPAS) <a id=\"tanh\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c858449",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "161ba41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 1e-05\n",
      "epochs: 150\n",
      "batches: 100\n"
     ]
    }
   ],
   "source": [
    "#alpha = 1e-5 # 0.00001\n",
    "#epochs = 50\n",
    "#batches = 256\n",
    "hidden1 = tanh\n",
    "hidden2 = tanh\n",
    "hidden3 = tanh\n",
    "out_layer = sigmoid\n",
    "print(f\"learning rate: {alpha}\")\n",
    "print(f\"epochs: {epochs}\")\n",
    "print(f\"batches: {batches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780c0445",
   "metadata": {},
   "source": [
    "#### Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee868f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of MLP(\n",
      "  (linear_stack): Sequential(\n",
      "    (0): Linear(in_features=27, out_features=18, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=18, out_features=12, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=12, out_features=8, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=8, out_features=1, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# instantiate model\n",
    "model = MLP(X_train.shape[1], hidden1, hidden2, hidden3, out_layer).to(device)\n",
    "\n",
    "# select optimizing function\n",
    "optimizer = adam(model.parameters(), lr=alpha)\n",
    "\n",
    "# select loss function\n",
    "loss_function = mse\n",
    "\n",
    "# accuracy metric\n",
    "metric = torchmetrics.functional.accuracy\n",
    "\n",
    "# display model\n",
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ca4bc2",
   "metadata": {},
   "source": [
    "#### Training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dece8a90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 150\n",
      "\tTraining\tAccuracy: 0.4117647111\tLoss: 0.2543039322\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2505727914\n",
      "Epoch 2 / 150\n",
      "\tTraining\tAccuracy: 0.4117647111\tLoss: 0.2536374927\n",
      "\tTest error\tAccuracy: 0.4109589159\tLoss: 0.2499907620\n",
      "Epoch 3 / 150\n",
      "\tTraining\tAccuracy: 0.4117647111\tLoss: 0.2529648542\n",
      "\tTest error\tAccuracy: 0.4246575236\tLoss: 0.2494086623\n",
      "Epoch 4 / 150\n",
      "\tTraining\tAccuracy: 0.4117647111\tLoss: 0.2522921264\n",
      "\tTest error\tAccuracy: 0.4246575236\tLoss: 0.2488209307\n",
      "Epoch 5 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2516234815\n",
      "\tTest error\tAccuracy: 0.4246575236\tLoss: 0.2482315983\n",
      "Epoch 6 / 150\n",
      "\tTraining\tAccuracy: 0.4705882370\tLoss: 0.2509469688\n",
      "\tTest error\tAccuracy: 0.4657534361\tLoss: 0.2476400946\n",
      "Epoch 7 / 150\n",
      "\tTraining\tAccuracy: 0.5294117928\tLoss: 0.2502631545\n",
      "\tTest error\tAccuracy: 0.4794520438\tLoss: 0.2470382360\n",
      "Epoch 8 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2495728731\n",
      "\tTest error\tAccuracy: 0.5068492889\tLoss: 0.2464318602\n",
      "Epoch 9 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2488802522\n",
      "\tTest error\tAccuracy: 0.5205479264\tLoss: 0.2458152182\n",
      "Epoch 10 / 150\n",
      "\tTraining\tAccuracy: 0.6176470518\tLoss: 0.2481682152\n",
      "\tTest error\tAccuracy: 0.5479452014\tLoss: 0.2451907254\n",
      "Epoch 11 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2474481314\n",
      "\tTest error\tAccuracy: 0.5753424764\tLoss: 0.2445544813\n",
      "Epoch 12 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2467172295\n",
      "\tTest error\tAccuracy: 0.6164383292\tLoss: 0.2439069273\n",
      "Epoch 13 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2459750772\n",
      "\tTest error\tAccuracy: 0.6301369667\tLoss: 0.2432501316\n",
      "Epoch 14 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2452200204\n",
      "\tTest error\tAccuracy: 0.6438356042\tLoss: 0.2425758519\n",
      "Epoch 15 / 150\n",
      "\tTraining\tAccuracy: 0.7352941036\tLoss: 0.2444502562\n",
      "\tTest error\tAccuracy: 0.6849315166\tLoss: 0.2418907150\n",
      "Epoch 16 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2436576784\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2411845099\n",
      "Epoch 17 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2428594530\n",
      "\tTest error\tAccuracy: 0.7671232820\tLoss: 0.2404694820\n",
      "Epoch 18 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2420352548\n",
      "\tTest error\tAccuracy: 0.7808219194\tLoss: 0.2397376377\n",
      "Epoch 19 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2412066162\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2389881703\n",
      "Epoch 20 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2403513938\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2382164150\n",
      "Epoch 21 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2394756973\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.2374368487\n",
      "Epoch 22 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2385980338\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2366485447\n",
      "Epoch 23 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2376850396\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2358288737\n",
      "Epoch 24 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2367639244\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2349998696\n",
      "Epoch 25 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2358230203\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.2341519317\n",
      "Epoch 26 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2348677516\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.2332902870\n",
      "Epoch 27 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2338883430\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.2324115293\n",
      "Epoch 28 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2329039574\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.2315194209\n",
      "Epoch 29 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2318982035\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.2306194951\n",
      "Epoch 30 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2308823764\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.2296967343\n",
      "Epoch 31 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2298481911\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.2287658240\n",
      "Epoch 32 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2287974060\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2278201594\n",
      "Epoch 33 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2277309448\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2268604877\n",
      "Epoch 34 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2266623974\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2258984404\n",
      "Epoch 35 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2255672663\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.2249118565\n",
      "Epoch 36 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2244657874\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2239221590\n",
      "Epoch 37 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2233658284\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2229310537\n",
      "Epoch 38 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2222384363\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2219143999\n",
      "Epoch 39 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2211143374\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2209081685\n",
      "Epoch 40 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2199758887\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2198731651\n",
      "Epoch 41 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2188173383\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.2188328100\n",
      "Epoch 42 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2176591903\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.2177948469\n",
      "Epoch 43 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2164953500\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.2167380445\n",
      "Epoch 44 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2153111100\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.2156742627\n",
      "Epoch 45 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2141342014\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2146089162\n",
      "Epoch 46 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2129485011\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2135387773\n",
      "Epoch 47 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2117508799\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2124730789\n",
      "Epoch 48 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2105474323\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2113816696\n",
      "Epoch 49 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2093297988\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2102850874\n",
      "Epoch 50 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2081349045\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2092129304\n",
      "Epoch 51 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2069135308\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2081116573\n",
      "Epoch 52 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2056950182\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2070123170\n",
      "Epoch 53 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2044840604\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2059114292\n",
      "Epoch 54 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2032557726\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2048124841\n",
      "Epoch 55 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2020252645\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2036911278\n",
      "Epoch 56 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2007925361\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2025812580\n",
      "Epoch 57 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1995629668\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2014724208\n",
      "Epoch 58 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1983315498\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2003593409\n",
      "Epoch 59 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1970930398\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1992375829\n",
      "Epoch 60 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1958641410\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1981206529\n",
      "Epoch 61 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1946390122\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1970095925\n",
      "Epoch 62 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1933891028\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1958776954\n",
      "Epoch 63 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1921705008\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1947766308\n",
      "Epoch 64 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1909170151\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1936283757\n",
      "Epoch 65 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1896987259\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1925191049\n",
      "Epoch 66 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1884465516\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1913832447\n",
      "Epoch 67 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1872208565\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1902798741\n",
      "Epoch 68 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1860031784\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1891555829\n",
      "Epoch 69 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1847599000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1880296611\n",
      "Epoch 70 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1835405380\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1869065882\n",
      "Epoch 71 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1822725534\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1857641701\n",
      "Epoch 72 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1810634583\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1846596279\n",
      "Epoch 73 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1798195243\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1835189951\n",
      "Epoch 74 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1785971075\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1824025817\n",
      "Epoch 75 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1773921251\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1812931264\n",
      "Epoch 76 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1761306226\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1801400951\n",
      "Epoch 77 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1749187112\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1790254201\n",
      "Epoch 78 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1737017930\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1778949662\n",
      "Epoch 79 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1724398732\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1767494026\n",
      "Epoch 80 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1712232977\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1756351505\n",
      "Epoch 81 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1700148582\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1744963541\n",
      "Epoch 82 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1687656790\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1733668716\n",
      "Epoch 83 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1675356776\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1722413280\n",
      "Epoch 84 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1663142145\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1711052834\n",
      "Epoch 85 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1650685966\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1699567302\n",
      "Epoch 86 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1638514847\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1688363112\n",
      "Epoch 87 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1626370400\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1677114041\n",
      "Epoch 88 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1613610089\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1665344089\n",
      "Epoch 89 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1601539105\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1654049477\n",
      "Epoch 90 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1589435190\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1642874777\n",
      "Epoch 91 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1577110291\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1631238773\n",
      "Epoch 92 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1564488113\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1619690451\n",
      "Epoch 93 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1552245617\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1608245642\n",
      "Epoch 94 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1540061384\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1596945709\n",
      "Epoch 95 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1527656615\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1585329615\n",
      "Epoch 96 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1515252739\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1573670556\n",
      "Epoch 97 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1502874792\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1562237371\n",
      "Epoch 98 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1490676254\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1550898658\n",
      "Epoch 99 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1478343010\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1539236598\n",
      "Epoch 100 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1466171592\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1527818633\n",
      "Epoch 101 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1453583688\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1515997996\n",
      "Epoch 102 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1441342831\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1504527721\n",
      "Epoch 103 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1429078430\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1493061497\n",
      "Epoch 104 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1416534334\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1481315238\n",
      "Epoch 105 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1404393613\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1469915268\n",
      "Epoch 106 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1392229944\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1458311429\n",
      "Epoch 107 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1380019188\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1446823215\n",
      "Epoch 108 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1367636472\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1435236143\n",
      "Epoch 109 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1355495304\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1423851017\n",
      "Epoch 110 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1343053877\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1412108980\n",
      "Epoch 111 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1331008524\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1400773178\n",
      "Epoch 112 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1318765581\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1389176739\n",
      "Epoch 113 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1306760162\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1377758519\n",
      "Epoch 114 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1294604540\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1366407332\n",
      "Epoch 115 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1282488555\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1354909873\n",
      "Epoch 116 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1270530671\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1343501789\n",
      "Epoch 117 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1258596033\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1332064118\n",
      "Epoch 118 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1246486530\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1320677964\n",
      "Epoch 119 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1234443858\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1309323818\n",
      "Epoch 120 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1222671047\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1298148887\n",
      "Epoch 121 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1210999340\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1286866431\n",
      "Epoch 122 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1199264526\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1275797568\n",
      "Epoch 123 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1187694743\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1264797332\n",
      "Epoch 124 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1175948456\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1253559887\n",
      "Epoch 125 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1164472252\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1242650442\n",
      "Epoch 126 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1153108999\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1231798842\n",
      "Epoch 127 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1141628250\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1220705268\n",
      "Epoch 128 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1130283698\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1209893184\n",
      "Epoch 129 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1118972749\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1199196102\n",
      "Epoch 130 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1107690185\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1188397209\n",
      "Epoch 131 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1096709743\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1177711902\n",
      "Epoch 132 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1085745171\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1167231472\n",
      "Epoch 133 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1074855626\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1156798491\n",
      "Epoch 134 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1064035371\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1146392875\n",
      "Epoch 135 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1053426042\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1136112472\n",
      "Epoch 136 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1042624265\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1125804860\n",
      "Epoch 137 / 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1031968296\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1115540592\n",
      "Epoch 138 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1021637619\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1105535591\n",
      "Epoch 139 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1011267304\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1095575378\n",
      "Epoch 140 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1000872627\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1085487076\n",
      "Epoch 141 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0990645513\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1075586304\n",
      "Epoch 142 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0980521441\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1065826916\n",
      "Epoch 143 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0970551744\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1056215284\n",
      "Epoch 144 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0960655883\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1046582780\n",
      "Epoch 145 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0950858444\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1036981752\n",
      "Epoch 146 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0941330269\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1027688459\n",
      "Epoch 147 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0931606144\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1018367651\n",
      "Epoch 148 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0922325402\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1009245671\n",
      "Epoch 149 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0912841037\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.0999964238\n",
      "Epoch 150 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0903579369\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.0990883783\n",
      "Finished\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * \n",
      "Execution time (in seconds): 21.49524105800083\n"
     ]
    }
   ],
   "source": [
    "training_results = []\n",
    "training_losses = []\n",
    "testing_results = []\n",
    "\n",
    "training_results, training_losses, testing_results = evaluate(training_s,\n",
    "                                                            test_s,\n",
    "                                                            model,\n",
    "                                                            loss_function,\n",
    "                                                            metric,\n",
    "                                                            optimizer,\n",
    "                                                            epochs,\n",
    "                                                            early_stop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57043a04",
   "metadata": {},
   "source": [
    "#### Prepare tanh results for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3cf086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tailend = f\"Tanh ({prefix})\"\n",
    "\n",
    "train_preds, test_preds = prep(tailend, training_results, testing_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fbb7ed",
   "metadata": {},
   "source": [
    "#### Generate tensorboard summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5baf5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensorboard(tailend, directory, training_s, train_preds, test_preds, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd1d008",
   "metadata": {},
   "source": [
    "#### Store Tanh results in dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd2c0185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compas_tanh_mk2_FTU.pth has been saved.\n"
     ]
    }
   ],
   "source": [
    "df[\"pred_tanh\"] = np.array(np.round(test_preds[-1])).astype(int)\n",
    "name = f\"{prefix}_tanh_{suffix}.pth\"\n",
    "custom_save(name, model)\n",
    "#torch.save(model, f\"{prefix}_tanh_scaled.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "20bc6f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat_25to45</th>\n",
       "      <th>age_cat_over45</th>\n",
       "      <th>age_cat_under25</th>\n",
       "      <th>race_asian</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>score_text_High</th>\n",
       "      <th>score_text_Low</th>\n",
       "      <th>score_text_Medium</th>\n",
       "      <th>v_score_text_High</th>\n",
       "      <th>v_score_text_Low</th>\n",
       "      <th>v_score_text_Medium</th>\n",
       "      <th>event</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>native</th>\n",
       "      <th>other</th>\n",
       "      <th>target</th>\n",
       "      <th>pred_relu</th>\n",
       "      <th>pred_tanh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1171</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  juv_fel_count  decile_score  juv_misd_count  juv_other_count  \\\n",
       "0   25              0             5               0                1   \n",
       "1   35              0             4               0                0   \n",
       "2   32              0             4               0                0   \n",
       "3   20              0            10               0                0   \n",
       "4   50              0             8               0                2   \n",
       "\n",
       "   priors_count  days_b_screening_arrest  c_days_from_compas  is_recid  \\\n",
       "0             4                       -1                   1         1   \n",
       "1             3                       -1                   0         1   \n",
       "2             1                        0                   0         0   \n",
       "3             0                       -1                   1         1   \n",
       "4            24                        0                   1         1   \n",
       "\n",
       "   is_violent_recid  decile_score.1  v_decile_score  priors_count.1  start  \\\n",
       "0                 0               5               4               4     32   \n",
       "1                 0               4               4               3      9   \n",
       "2                 0               4               3               1      0   \n",
       "3                 1              10              10               0      3   \n",
       "4                 1               8               8              24     32   \n",
       "\n",
       "    end  sex  age_cat_25to45  age_cat_over45  age_cat_under25  race_asian  \\\n",
       "0   304    0               1               0                0           0   \n",
       "1   462    0               1               0                0           0   \n",
       "2  1171    0               1               0                0           0   \n",
       "3    20    0               0               0                1           0   \n",
       "4    87    0               0               1                0           0   \n",
       "\n",
       "   c_charge_degree  score_text_High  score_text_Low  score_text_Medium  \\\n",
       "0                1                0               0                  1   \n",
       "1                0                0               1                  0   \n",
       "2                1                0               1                  0   \n",
       "3                0                1               0                  0   \n",
       "4                0                1               0                  0   \n",
       "\n",
       "   v_score_text_High  v_score_text_Low  v_score_text_Medium  event  black  \\\n",
       "0                  0                 1                    0      1      1   \n",
       "1                  0                 1                    0      1      0   \n",
       "2                  0                 1                    0      0      1   \n",
       "3                  1                 0                    0      1      1   \n",
       "4                  1                 0                    0      0      1   \n",
       "\n",
       "   white  hispanic  native  other  target  pred_relu  pred_tanh  \n",
       "0      0         0       0      0       1          1          1  \n",
       "1      1         0       0      0       1          1          1  \n",
       "2      0         0       0      0       0          0          0  \n",
       "3      0         0       0      0       1          1          1  \n",
       "4      0         0       0      0       1          1          1  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dd5871",
   "metadata": {},
   "source": [
    "## Trial 3.3 - ELU (COMPAS)<a id=\"elu\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1f8673",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7907eaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 1e-05\n",
      "epochs: 150\n",
      "batches: 100\n"
     ]
    }
   ],
   "source": [
    "#alpha = 1e-5 # 0.00001\n",
    "#epochs = 50\n",
    "#batches = 256\n",
    "hidden1 = elu\n",
    "hidden2 = elu\n",
    "hidden3 = elu\n",
    "out_layer = sigmoid\n",
    "print(f\"learning rate: {alpha}\")\n",
    "print(f\"epochs: {epochs}\")\n",
    "print(f\"batches: {batches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79df8ba0",
   "metadata": {},
   "source": [
    "#### Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f411ba08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of MLP(\n",
      "  (linear_stack): Sequential(\n",
      "    (0): Linear(in_features=27, out_features=18, bias=True)\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): Linear(in_features=18, out_features=12, bias=True)\n",
      "    (3): ELU(alpha=1.0)\n",
      "    (4): Linear(in_features=12, out_features=8, bias=True)\n",
      "    (5): ELU(alpha=1.0)\n",
      "    (6): Linear(in_features=8, out_features=1, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# instantiate model\n",
    "model = MLP(X_train.shape[1], hidden1, hidden2, hidden3, out_layer).to(device)\n",
    "\n",
    "# select optimizing function\n",
    "optimizer = adam(model.parameters(), lr=alpha)\n",
    "\n",
    "# select loss function\n",
    "criterion = mse\n",
    "\n",
    "# accuracy metric\n",
    "metric = torchmetrics.functional.accuracy\n",
    "\n",
    "# display model\n",
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91ba9ad",
   "metadata": {},
   "source": [
    "#### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b75c1dfd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2476783395\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2511324812\n",
      "Epoch 2 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2472200990\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2507132285\n",
      "Epoch 3 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2467676550\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2502936536\n",
      "Epoch 4 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2463148981\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2498707835\n",
      "Epoch 5 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2458629012\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2494533019\n",
      "Epoch 6 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2454108149\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2490300742\n",
      "Epoch 7 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2449523211\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2486070387\n",
      "Epoch 8 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2444974929\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2481863279\n",
      "Epoch 9 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2440366149\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2477552501\n",
      "Epoch 10 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2435650826\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2473227084\n",
      "Epoch 11 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2430918068\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2468838961\n",
      "Epoch 12 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2426140159\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2464425145\n",
      "Epoch 13 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2421278059\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2459931196\n",
      "Epoch 14 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2416359335\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2455359499\n",
      "Epoch 15 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2411384583\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2450766280\n",
      "Epoch 16 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2406274080\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2446085917\n",
      "Epoch 17 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2401161492\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2441361724\n",
      "Epoch 18 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2395919412\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2436491641\n",
      "Epoch 19 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2390616983\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2431591579\n",
      "Epoch 20 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2385102212\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2426514122\n",
      "Epoch 21 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2379584014\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2421428277\n",
      "Epoch 22 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2373905182\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2416174312\n",
      "Epoch 23 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2368214279\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2410893313\n",
      "Epoch 24 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2362259477\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2405441928\n",
      "Epoch 25 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2356285751\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2399945188\n",
      "Epoch 26 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2350190133\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2394333865\n",
      "Epoch 27 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2343964875\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2388569606\n",
      "Epoch 28 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2337605059\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2382738675\n",
      "Epoch 29 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2331135571\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2376790423\n",
      "Epoch 30 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2324541062\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2370709741\n",
      "Epoch 31 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2317758799\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2364455284\n",
      "Epoch 32 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2310879230\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2358138299\n",
      "Epoch 33 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2303895056\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2351694277\n",
      "Epoch 34 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2296715379\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2345152930\n",
      "Epoch 35 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2289448977\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2338402775\n",
      "Epoch 36 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2282067090\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2331573850\n",
      "Epoch 37 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2274489403\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2324664288\n",
      "Epoch 38 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2266821116\n",
      "\tTest error\tAccuracy: 0.6164383292\tLoss: 0.2317527050\n",
      "Epoch 39 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2259053141\n",
      "\tTest error\tAccuracy: 0.6301369667\tLoss: 0.2310394276\n",
      "Epoch 40 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2251085043\n",
      "\tTest error\tAccuracy: 0.6438356042\tLoss: 0.2303085895\n",
      "Epoch 41 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2243016660\n",
      "\tTest error\tAccuracy: 0.6575342417\tLoss: 0.2295604015\n",
      "Epoch 42 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2234736532\n",
      "\tTest error\tAccuracy: 0.6712328792\tLoss: 0.2288053944\n",
      "Epoch 43 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2226462364\n",
      "\tTest error\tAccuracy: 0.6712328792\tLoss: 0.2280319837\n",
      "Epoch 44 / 150\n",
      "\tTraining\tAccuracy: 0.6470588446\tLoss: 0.2217955142\n",
      "\tTest error\tAccuracy: 0.7123287916\tLoss: 0.2272620740\n",
      "Epoch 45 / 150\n",
      "\tTraining\tAccuracy: 0.6470588446\tLoss: 0.2209270298\n",
      "\tTest error\tAccuracy: 0.7123287916\tLoss: 0.2264549079\n",
      "Epoch 46 / 150\n",
      "\tTraining\tAccuracy: 0.6470588446\tLoss: 0.2200578004\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2256585565\n",
      "Epoch 47 / 150\n",
      "\tTraining\tAccuracy: 0.6470588446\tLoss: 0.2191706598\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2248431494\n",
      "Epoch 48 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2182621807\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2240091747\n",
      "Epoch 49 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2173532546\n",
      "\tTest error\tAccuracy: 0.7534246445\tLoss: 0.2231699824\n",
      "Epoch 50 / 150\n",
      "\tTraining\tAccuracy: 0.7352941036\tLoss: 0.2164337784\n",
      "\tTest error\tAccuracy: 0.7534246445\tLoss: 0.2223230054\n",
      "Epoch 51 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2154921144\n",
      "\tTest error\tAccuracy: 0.7534246445\tLoss: 0.2214570549\n",
      "Epoch 52 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2145414054\n",
      "\tTest error\tAccuracy: 0.7671232820\tLoss: 0.2205882555\n",
      "Epoch 53 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2135774195\n",
      "\tTest error\tAccuracy: 0.7808219194\tLoss: 0.2197036630\n",
      "Epoch 54 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2126041055\n",
      "\tTest error\tAccuracy: 0.7808219194\tLoss: 0.2188011301\n",
      "Epoch 55 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2116205096\n",
      "\tTest error\tAccuracy: 0.7945205569\tLoss: 0.2178973627\n",
      "Epoch 56 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2106215805\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2169827592\n",
      "Epoch 57 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2096255422\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.2160640146\n",
      "Epoch 58 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2085904926\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.2151078780\n",
      "Epoch 59 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2075598985\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.2141684131\n",
      "Epoch 60 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2065243870\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.2132187181\n",
      "Epoch 61 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2054743171\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2122475292\n",
      "Epoch 62 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2044108063\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2112669633\n",
      "Epoch 63 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2033426017\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2102901205\n",
      "Epoch 64 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2022761256\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2092992209\n",
      "Epoch 65 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2011912912\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2083018167\n",
      "Epoch 66 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2000924349\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2072936155\n",
      "Epoch 67 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.1989870816\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2062804294\n",
      "Epoch 68 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.1978769302\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2052582864\n",
      "Epoch 69 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.1967584044\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2042293882\n",
      "Epoch 70 / 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.1956461817\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2031952725\n",
      "Epoch 71 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.1945047379\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2021525509\n",
      "Epoch 72 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.1933717877\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2011040776\n",
      "Epoch 73 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.1922188997\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2000398792\n",
      "Epoch 74 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.1910829246\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1989885122\n",
      "Epoch 75 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.1899308264\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.1979228294\n",
      "Epoch 76 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.1887672693\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.1968534028\n",
      "Epoch 77 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.1876121759\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.1957783713\n",
      "Epoch 78 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.1864346117\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.1947003773\n",
      "Epoch 79 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.1852726042\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.1936209805\n",
      "Epoch 80 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.1840889901\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.1925221235\n",
      "Epoch 81 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.1829227358\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.1914417815\n",
      "Epoch 82 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1817475706\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.1903488146\n",
      "Epoch 83 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1805614829\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.1892432393\n",
      "Epoch 84 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1793906838\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.1881428141\n",
      "Epoch 85 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1781988144\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.1870464683\n",
      "Epoch 86 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1770110875\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1859374039\n",
      "Epoch 87 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1758255363\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1848169182\n",
      "Epoch 88 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1746173203\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1837058898\n",
      "Epoch 89 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1734266877\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1825748285\n",
      "Epoch 90 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1722387075\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1814691190\n",
      "Epoch 91 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1710399538\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1803462974\n",
      "Epoch 92 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1698323637\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1792159854\n",
      "Epoch 93 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1686431617\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1780893192\n",
      "Epoch 94 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1674496979\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1769675754\n",
      "Epoch 95 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1662499756\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1758315854\n",
      "Epoch 96 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1650417298\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1746969216\n",
      "Epoch 97 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1638571173\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1735702327\n",
      "Epoch 98 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1626464725\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1724227135\n",
      "Epoch 99 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1614409834\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1712800520\n",
      "Epoch 100 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1602479219\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1701351496\n",
      "Epoch 101 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1590408385\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1689862133\n",
      "Epoch 102 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1578399092\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1678426819\n",
      "Epoch 103 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1566491723\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1666913487\n",
      "Epoch 104 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1554324180\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1655419632\n",
      "Epoch 105 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1542437822\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1643871353\n",
      "Epoch 106 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1530343294\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1632216246\n",
      "Epoch 107 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1518171430\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1620599372\n",
      "Epoch 108 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1506051719\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1608944329\n",
      "Epoch 109 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1494140327\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1597347025\n",
      "Epoch 110 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1482119858\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1585691323\n",
      "Epoch 111 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1469952464\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1573855132\n",
      "Epoch 112 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1457874030\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1562164362\n",
      "Epoch 113 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1445947289\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1550420764\n",
      "Epoch 114 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1433816403\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1538579712\n",
      "Epoch 115 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1421685219\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1526847482\n",
      "Epoch 116 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1409592927\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1514995637\n",
      "Epoch 117 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1397332102\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1503051676\n",
      "Epoch 118 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1385397166\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1491303267\n",
      "Epoch 119 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1373146027\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1479289936\n",
      "Epoch 120 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1360970438\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1467340134\n",
      "Epoch 121 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1348901391\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1455389027\n",
      "Epoch 122 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1336473674\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1443210028\n",
      "Epoch 123 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1324364543\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1431271778\n",
      "Epoch 124 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1312408447\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1419269843\n",
      "Epoch 125 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1300141662\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1407161376\n",
      "Epoch 126 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1287947893\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1395143107\n",
      "Epoch 127 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1275784224\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1383046302\n",
      "Epoch 128 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1263686419\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1370897240\n",
      "Epoch 129 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1251228899\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1358684202\n",
      "Epoch 130 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1239051372\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1346661637\n",
      "Epoch 131 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1226873696\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1334504897\n",
      "Epoch 132 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1214637309\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1322370207\n",
      "Epoch 133 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1202469468\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1310161863\n",
      "Epoch 134 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1190172061\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1297822971\n",
      "Epoch 135 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1177895516\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1285703434\n",
      "Epoch 136 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1165786088\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1273509523\n",
      "Epoch 137 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1153473705\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1261289134\n",
      "Epoch 138 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1141351834\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1249125068\n",
      "Epoch 139 / 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1129222512\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1237063834\n",
      "Epoch 140 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1117158905\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1224985928\n",
      "Epoch 141 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1105018482\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1212722922\n",
      "Epoch 142 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1093001664\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1200640265\n",
      "Epoch 143 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1080906764\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1188549236\n",
      "Epoch 144 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1068835407\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1176474215\n",
      "Epoch 145 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1056938469\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1164503310\n",
      "Epoch 146 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1044935882\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1152470640\n",
      "Epoch 147 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1033017933\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1140510482\n",
      "Epoch 148 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1021216363\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1128665627\n",
      "Epoch 149 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1009389460\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1116674613\n",
      "Epoch 150 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.0997535065\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1104846870\n",
      "Finished\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * \n",
      "Execution time (in seconds): 19.33227065700339\n"
     ]
    }
   ],
   "source": [
    "training_results = []\n",
    "training_losses = []\n",
    "testing_results = []\n",
    "\n",
    "training_results, training_losses, testing_results = evaluate(training_s,\n",
    "                                                            test_s,\n",
    "                                                            model,\n",
    "                                                            loss_function,\n",
    "                                                            metric,\n",
    "                                                            optimizer,\n",
    "                                                            epochs,\n",
    "                                                            early_stop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ff80b",
   "metadata": {},
   "source": [
    "#### Prepare ELU results for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8e93287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tailend = f\"ELU ({prefix})\"\n",
    "\n",
    "train_preds, test_preds = prep(tailend, training_results, testing_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fb14be",
   "metadata": {},
   "source": [
    "#### Save metrics to tensorboad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "18bbfa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensorboard(tailend, directory, training_s, train_preds, test_preds, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477d283c",
   "metadata": {},
   "source": [
    "#### Add ELU test results to persistent storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7f44fd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compas_elu_mk2_FTU.pth has been saved.\n"
     ]
    }
   ],
   "source": [
    "df[\"pred_elu\"] = np.array(np.round(test_preds[-1])).astype(int)\n",
    "name = f\"{prefix}_elu_{suffix}.pth\"\n",
    "custom_save(name, model, 1)\n",
    "#torch.save(model, f\"{prefix}_elu_scaled.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb977740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat_25to45</th>\n",
       "      <th>age_cat_over45</th>\n",
       "      <th>age_cat_under25</th>\n",
       "      <th>race_asian</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>score_text_High</th>\n",
       "      <th>score_text_Low</th>\n",
       "      <th>score_text_Medium</th>\n",
       "      <th>v_score_text_High</th>\n",
       "      <th>v_score_text_Low</th>\n",
       "      <th>v_score_text_Medium</th>\n",
       "      <th>event</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>native</th>\n",
       "      <th>other</th>\n",
       "      <th>target</th>\n",
       "      <th>pred_relu</th>\n",
       "      <th>pred_tanh</th>\n",
       "      <th>pred_elu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1171</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  juv_fel_count  decile_score  juv_misd_count  juv_other_count  \\\n",
       "0   25              0             5               0                1   \n",
       "1   35              0             4               0                0   \n",
       "2   32              0             4               0                0   \n",
       "3   20              0            10               0                0   \n",
       "4   50              0             8               0                2   \n",
       "\n",
       "   priors_count  days_b_screening_arrest  c_days_from_compas  is_recid  \\\n",
       "0             4                       -1                   1         1   \n",
       "1             3                       -1                   0         1   \n",
       "2             1                        0                   0         0   \n",
       "3             0                       -1                   1         1   \n",
       "4            24                        0                   1         1   \n",
       "\n",
       "   is_violent_recid  decile_score.1  v_decile_score  priors_count.1  start  \\\n",
       "0                 0               5               4               4     32   \n",
       "1                 0               4               4               3      9   \n",
       "2                 0               4               3               1      0   \n",
       "3                 1              10              10               0      3   \n",
       "4                 1               8               8              24     32   \n",
       "\n",
       "    end  sex  age_cat_25to45  age_cat_over45  age_cat_under25  race_asian  \\\n",
       "0   304    0               1               0                0           0   \n",
       "1   462    0               1               0                0           0   \n",
       "2  1171    0               1               0                0           0   \n",
       "3    20    0               0               0                1           0   \n",
       "4    87    0               0               1                0           0   \n",
       "\n",
       "   c_charge_degree  score_text_High  score_text_Low  score_text_Medium  \\\n",
       "0                1                0               0                  1   \n",
       "1                0                0               1                  0   \n",
       "2                1                0               1                  0   \n",
       "3                0                1               0                  0   \n",
       "4                0                1               0                  0   \n",
       "\n",
       "   v_score_text_High  v_score_text_Low  v_score_text_Medium  event  black  \\\n",
       "0                  0                 1                    0      1      1   \n",
       "1                  0                 1                    0      1      0   \n",
       "2                  0                 1                    0      0      1   \n",
       "3                  1                 0                    0      1      1   \n",
       "4                  1                 0                    0      0      1   \n",
       "\n",
       "   white  hispanic  native  other  target  pred_relu  pred_tanh  pred_elu  \n",
       "0      0         0       0      0       1          1          1         1  \n",
       "1      1         0       0      0       1          1          1         1  \n",
       "2      0         0       0      0       0          0          0         0  \n",
       "3      0         0       0      0       1          1          1         1  \n",
       "4      0         0       0      0       1          1          1         1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56a11fb",
   "metadata": {},
   "source": [
    "## Trial 3.4 - Leaky ReLU (COMPAS) <a id=\"leaky\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c12bb62",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d637e9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 1e-05\n",
      "epochs: 150\n",
      "batches: 100\n"
     ]
    }
   ],
   "source": [
    "#alpha = 1e-5 # 0.00001\n",
    "#epochs = 50\n",
    "#batches = 256\n",
    "hidden1 = leaky\n",
    "hidden2 = leaky\n",
    "hidden3 = leaky\n",
    "out_layer = sigmoid\n",
    "print(f\"learning rate: {alpha}\")\n",
    "print(f\"epochs: {epochs}\")\n",
    "print(f\"batches: {batches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07d24f5",
   "metadata": {},
   "source": [
    "#### Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "661fff72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of MLP(\n",
      "  (linear_stack): Sequential(\n",
      "    (0): Linear(in_features=27, out_features=18, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=18, out_features=12, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=12, out_features=8, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Linear(in_features=8, out_features=1, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# instantiate model\n",
    "model = MLP(X_train.shape[1], hidden1, hidden2, hidden3, out_layer).to(device)\n",
    "\n",
    "# select optimizing function\n",
    "optimizer = adam(model.parameters(), lr=alpha)\n",
    "\n",
    "# select loss function\n",
    "criterion = mse\n",
    "\n",
    "# accuracy metric\n",
    "metric = torchmetrics.functional.accuracy\n",
    "\n",
    "# display model\n",
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321e45bf",
   "metadata": {},
   "source": [
    "#### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e5cfcf9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2483161539\n",
      "\tTest error\tAccuracy: 0.6164383292\tLoss: 0.2481228773\n",
      "Epoch 2 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2480029464\n",
      "\tTest error\tAccuracy: 0.6301369667\tLoss: 0.2478469199\n",
      "Epoch 3 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2476756424\n",
      "\tTest error\tAccuracy: 0.6438356042\tLoss: 0.2475536728\n",
      "Epoch 4 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2473300993\n",
      "\tTest error\tAccuracy: 0.6438356042\tLoss: 0.2472428864\n",
      "Epoch 5 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2469552904\n",
      "\tTest error\tAccuracy: 0.6575342417\tLoss: 0.2469156789\n",
      "Epoch 6 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2465411425\n",
      "\tTest error\tAccuracy: 0.6849315166\tLoss: 0.2465683257\n",
      "Epoch 7 / 150\n",
      "\tTraining\tAccuracy: 0.7352941036\tLoss: 0.2461168617\n",
      "\tTest error\tAccuracy: 0.7260273695\tLoss: 0.2462090644\n",
      "Epoch 8 / 150\n",
      "\tTraining\tAccuracy: 0.7352941036\tLoss: 0.2456738204\n",
      "\tTest error\tAccuracy: 0.7534246445\tLoss: 0.2458360756\n",
      "Epoch 9 / 150\n",
      "\tTraining\tAccuracy: 0.7352941036\tLoss: 0.2452338487\n",
      "\tTest error\tAccuracy: 0.7808219194\tLoss: 0.2454505492\n",
      "Epoch 10 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2447857261\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2450470527\n",
      "Epoch 11 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2443337739\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2446332177\n",
      "Epoch 12 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2438747734\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2442095478\n",
      "Epoch 13 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2434038222\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2437745184\n",
      "Epoch 14 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2429244071\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.2433319567\n",
      "Epoch 15 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2424397171\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.2428810682\n",
      "Epoch 16 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2419564575\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.2424188945\n",
      "Epoch 17 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2414611131\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.2419514550\n",
      "Epoch 18 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2409730554\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.2414732866\n",
      "Epoch 19 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2404755950\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.2409865395\n",
      "Epoch 20 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2399672419\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.2404845229\n",
      "Epoch 21 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2394530326\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.2399769305\n",
      "Epoch 22 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2389265001\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.2394603675\n",
      "Epoch 23 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2383892685\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.2389349490\n",
      "Epoch 24 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2378505617\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.2384025639\n",
      "Epoch 25 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2373046875\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.2378638373\n",
      "Epoch 26 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2367493659\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.2373181440\n",
      "Epoch 27 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2361859977\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.2367674056\n",
      "Epoch 28 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2356275171\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.2362042112\n",
      "Epoch 29 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2350541502\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.2356361896\n",
      "Epoch 30 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2344684005\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2350698220\n",
      "Epoch 31 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2338705063\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2344888122\n",
      "Epoch 32 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2332635522\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2339010998\n",
      "Epoch 33 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2326397896\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2333033064\n",
      "Epoch 34 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2320093215\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2327004054\n",
      "Epoch 35 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2313743532\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2320946774\n",
      "Epoch 36 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2307288200\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2314723141\n",
      "Epoch 37 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2300780267\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2308448489\n",
      "Epoch 38 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2294107080\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2302110181\n",
      "Epoch 39 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2287383974\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2295651443\n",
      "Epoch 40 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2280501276\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2289162193\n",
      "Epoch 41 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2273609489\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2282579811\n",
      "Epoch 42 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2266738266\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.2276011514\n",
      "Epoch 43 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2259657532\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.2269314861\n",
      "Epoch 44 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2252445817\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.2262557908\n",
      "Epoch 45 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2245494872\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.2255788048\n",
      "Epoch 46 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2238468528\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.2248983128\n",
      "Epoch 47 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2231329232\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.2242052321\n",
      "Epoch 48 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2224164605\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.2235124892\n",
      "Epoch 49 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2217009217\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.2228139731\n",
      "Epoch 50 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2209746540\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.2221053094\n",
      "Epoch 51 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2202389687\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.2213932623\n",
      "Epoch 52 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2194883078\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.2206725861\n",
      "Epoch 53 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2187276781\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.2199486863\n",
      "Epoch 54 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2179746479\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.2192210647\n",
      "Epoch 55 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2172020823\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2184857989\n",
      "Epoch 56 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2164336890\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2177465750\n",
      "Epoch 57 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2156555951\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2169925649\n",
      "Epoch 58 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2148702294\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2162390742\n",
      "Epoch 59 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2140627503\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2154737810\n",
      "Epoch 60 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2132516801\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2147033804\n",
      "Epoch 61 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2124282122\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2139287350\n",
      "Epoch 62 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2116102874\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2131473493\n",
      "Epoch 63 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2107592374\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2123659941\n",
      "Epoch 64 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2099097520\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2115697634\n",
      "Epoch 65 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2090475410\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2107660274\n",
      "Epoch 66 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2081798464\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2099636516\n",
      "Epoch 67 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2073088437\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2091433761\n",
      "Epoch 68 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2064375281\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2083294250\n",
      "Epoch 69 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2055613250\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2075025524\n",
      "Epoch 70 / 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2046903521\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2066729885\n",
      "Epoch 71 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2038003653\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2058287469\n",
      "Epoch 72 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2029171884\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2049824255\n",
      "Epoch 73 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2020072043\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2041255967\n",
      "Epoch 74 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2010989189\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2032664177\n",
      "Epoch 75 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2001856714\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2024043401\n",
      "Epoch 76 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1992606223\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2015349837\n",
      "Epoch 77 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1983191222\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2006485654\n",
      "Epoch 78 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1973884553\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1997644419\n",
      "Epoch 79 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1964599937\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1988840678\n",
      "Epoch 80 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1954938918\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1979743774\n",
      "Epoch 81 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1945399642\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1970721497\n",
      "Epoch 82 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1935853511\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1961668254\n",
      "Epoch 83 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1925997883\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1952482434\n",
      "Epoch 84 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1916326284\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1943255798\n",
      "Epoch 85 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1906254143\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1933941146\n",
      "Epoch 86 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1896241158\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1924660525\n",
      "Epoch 87 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1886236519\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1915251804\n",
      "Epoch 88 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1875861734\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1905755401\n",
      "Epoch 89 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1865601987\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1896261871\n",
      "Epoch 90 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1855408996\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1886740526\n",
      "Epoch 91 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1845169365\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1877046568\n",
      "Epoch 92 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1834871024\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1867453151\n",
      "Epoch 93 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1824486405\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1857699504\n",
      "Epoch 94 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1813947856\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1847764821\n",
      "Epoch 95 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1803793460\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1838069615\n",
      "Epoch 96 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1793415099\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1828176010\n",
      "Epoch 97 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1783022285\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1818249389\n",
      "Epoch 98 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1772581190\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1808229181\n",
      "Epoch 99 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1762373447\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1798271977\n",
      "Epoch 100 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1751988232\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1788233930\n",
      "Epoch 101 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1741615683\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1778167117\n",
      "Epoch 102 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1731113791\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1767950470\n",
      "Epoch 103 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1720701456\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1757776688\n",
      "Epoch 104 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1710014343\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1747610690\n",
      "Epoch 105 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1699085534\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1737248479\n",
      "Epoch 106 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1688303351\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1726908464\n",
      "Epoch 107 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1677673608\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1716743701\n",
      "Epoch 108 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1667062491\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1706450475\n",
      "Epoch 109 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1656065136\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1695998446\n",
      "Epoch 110 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1645352393\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1685642976\n",
      "Epoch 111 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1634760648\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1675340242\n",
      "Epoch 112 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1624120623\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1664991343\n",
      "Epoch 113 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1613522768\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1654738273\n",
      "Epoch 114 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1602761000\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1644177806\n",
      "Epoch 115 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1591853052\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1633745411\n",
      "Epoch 116 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1581079215\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1623359961\n",
      "Epoch 117 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1570368707\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1612981104\n",
      "Epoch 118 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1559781134\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1602505616\n",
      "Epoch 119 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1549121588\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1592164948\n",
      "Epoch 120 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1538149118\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1581556513\n",
      "Epoch 121 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1527218223\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1571039806\n",
      "Epoch 122 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1516330540\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1560581014\n",
      "Epoch 123 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1505445242\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1550112984\n",
      "Epoch 124 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1494549960\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1539709242\n",
      "Epoch 125 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1483622044\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1529140047\n",
      "Epoch 126 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1472540200\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1518566147\n",
      "Epoch 127 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1461547464\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1507971897\n",
      "Epoch 128 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1450562477\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1497519995\n",
      "Epoch 129 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1439694166\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1486988281\n",
      "Epoch 130 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1428591162\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1476448164\n",
      "Epoch 131 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1417690516\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1465949955\n",
      "Epoch 132 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1406587958\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1455397187\n",
      "Epoch 133 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1395567507\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1444833566\n",
      "Epoch 134 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1384580731\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1434356364\n",
      "Epoch 135 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1373670101\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1423961630\n",
      "Epoch 136 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1362916380\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1413515412\n",
      "Epoch 137 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1352062076\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1403147220\n",
      "Epoch 138 / 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1341151297\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1392619471\n",
      "Epoch 139 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1330289096\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1382295833\n",
      "Epoch 140 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1319509596\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1371893095\n",
      "Epoch 141 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1308664382\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1361500326\n",
      "Epoch 142 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1297907531\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1351150118\n",
      "Epoch 143 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1287105381\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1340609051\n",
      "Epoch 144 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1276101321\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1330216992\n",
      "Epoch 145 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1265446991\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1319839873\n",
      "Epoch 146 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1254972219\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1309723535\n",
      "Epoch 147 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1244484410\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1299371084\n",
      "Epoch 148 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1233947426\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1289195241\n",
      "Epoch 149 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1223504022\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1278993445\n",
      "Epoch 150 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1212945133\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1268808561\n",
      "Finished\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * \n",
      "Execution time (in seconds): 19.208095351001248\n"
     ]
    }
   ],
   "source": [
    "training_results = []\n",
    "training_losses = []\n",
    "testing_results = []\n",
    "\n",
    "training_results, training_losses, testing_results = evaluate(training_s,\n",
    "                                                             test_s,\n",
    "                                                             model,\n",
    "                                                             loss_function,\n",
    "                                                             metric,\n",
    "                                                             optimizer,\n",
    "                                                             epochs,\n",
    "                                                             early_stop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3026827f",
   "metadata": {},
   "source": [
    "#### Prepare Leaky ReLU data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b33e2a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "tailend = f\"Leaky ReLU ({prefix})\"\n",
    "\n",
    "train_preds, test_preds = prep(tailend, training_results, testing_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f2436d",
   "metadata": {},
   "source": [
    "#### Add Leaky ReLU data to persistent storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ccb2f905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compas_leaky_mk2_FTU.pth has been saved.\n"
     ]
    }
   ],
   "source": [
    "df[\"pred_leaky\"] = np.array(np.round(test_preds[-1])).astype(int)\n",
    "name = f\"{prefix}_leaky_{suffix}.pth\"\n",
    "custom_save(name, model,1)\n",
    "# torch.save(model, \"loans_leaky_scaled.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "baa26181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat_25to45</th>\n",
       "      <th>age_cat_over45</th>\n",
       "      <th>age_cat_under25</th>\n",
       "      <th>race_asian</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>score_text_High</th>\n",
       "      <th>score_text_Low</th>\n",
       "      <th>score_text_Medium</th>\n",
       "      <th>v_score_text_High</th>\n",
       "      <th>v_score_text_Low</th>\n",
       "      <th>v_score_text_Medium</th>\n",
       "      <th>event</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>native</th>\n",
       "      <th>other</th>\n",
       "      <th>target</th>\n",
       "      <th>pred_relu</th>\n",
       "      <th>pred_tanh</th>\n",
       "      <th>pred_elu</th>\n",
       "      <th>pred_leaky</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1171</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  juv_fel_count  decile_score  juv_misd_count  juv_other_count  \\\n",
       "0   25              0             5               0                1   \n",
       "1   35              0             4               0                0   \n",
       "2   32              0             4               0                0   \n",
       "3   20              0            10               0                0   \n",
       "4   50              0             8               0                2   \n",
       "\n",
       "   priors_count  days_b_screening_arrest  c_days_from_compas  is_recid  \\\n",
       "0             4                       -1                   1         1   \n",
       "1             3                       -1                   0         1   \n",
       "2             1                        0                   0         0   \n",
       "3             0                       -1                   1         1   \n",
       "4            24                        0                   1         1   \n",
       "\n",
       "   is_violent_recid  decile_score.1  v_decile_score  priors_count.1  start  \\\n",
       "0                 0               5               4               4     32   \n",
       "1                 0               4               4               3      9   \n",
       "2                 0               4               3               1      0   \n",
       "3                 1              10              10               0      3   \n",
       "4                 1               8               8              24     32   \n",
       "\n",
       "    end  sex  age_cat_25to45  age_cat_over45  age_cat_under25  race_asian  \\\n",
       "0   304    0               1               0                0           0   \n",
       "1   462    0               1               0                0           0   \n",
       "2  1171    0               1               0                0           0   \n",
       "3    20    0               0               0                1           0   \n",
       "4    87    0               0               1                0           0   \n",
       "\n",
       "   c_charge_degree  score_text_High  score_text_Low  score_text_Medium  \\\n",
       "0                1                0               0                  1   \n",
       "1                0                0               1                  0   \n",
       "2                1                0               1                  0   \n",
       "3                0                1               0                  0   \n",
       "4                0                1               0                  0   \n",
       "\n",
       "   v_score_text_High  v_score_text_Low  v_score_text_Medium  event  black  \\\n",
       "0                  0                 1                    0      1      1   \n",
       "1                  0                 1                    0      1      0   \n",
       "2                  0                 1                    0      0      1   \n",
       "3                  1                 0                    0      1      1   \n",
       "4                  1                 0                    0      0      1   \n",
       "\n",
       "   white  hispanic  native  other  target  pred_relu  pred_tanh  pred_elu  \\\n",
       "0      0         0       0      0       1          1          1         1   \n",
       "1      1         0       0      0       1          1          1         1   \n",
       "2      0         0       0      0       0          0          0         0   \n",
       "3      0         0       0      0       1          1          1         1   \n",
       "4      0         0       0      0       1          1          1         1   \n",
       "\n",
       "   pred_leaky  \n",
       "0           1  \n",
       "1           1  \n",
       "2           0  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1422aae",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cecbae",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c83d1d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compas_results_mk2_FTU.parquet has been saved.\n"
     ]
    }
   ],
   "source": [
    "name = f\"{prefix}_results_{suffix}.parquet\"\n",
    "custom_save(name, df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09301c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
