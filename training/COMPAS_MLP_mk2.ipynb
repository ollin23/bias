{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33f1ba6e",
   "metadata": {},
   "source": [
    "# MLP with COMPAS Dataset - mk1\n",
    "#### 17 May 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822aba1b",
   "metadata": {},
   "source": [
    "## Load Dependencies <a id=\"libraries\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0acb8b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import timeit\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "321c01a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "882d8f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f073f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c5f98",
   "metadata": {},
   "source": [
    "### Notebook options and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7ceb224",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 250\n",
    "pd.options.display.max_rows = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f12b2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed for consistency in pytorch and numpy\n",
    "SEED = 23\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6076047e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24203bde",
   "metadata": {},
   "source": [
    "### Hyperparameter options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86559bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation functions\n",
    "elu = nn.ELU()\n",
    "leaky = nn.LeakyReLU()\n",
    "relu = nn.ReLU()\n",
    "tanh = nn.Tanh()\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "# loss functions\n",
    "mse = nn.MSELoss()\n",
    "bce = nn.BCELoss()\n",
    "kld = nn.KLDivLoss()\n",
    "\n",
    "# optimizers\n",
    "adam = torch.optim.Adam\n",
    "sgd = torch.optim.SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab62d8ef",
   "metadata": {},
   "source": [
    "## Custom Functions <a id=\"functions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba63d8d9",
   "metadata": {},
   "source": [
    "#### Create dataset for DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc43af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.X = torch.tensor(data, dtype=torch.float32, device=device)\n",
    "        self.y = torch.tensor(target, dtype=torch.float32, device=device)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20bf5a2",
   "metadata": {},
   "source": [
    "#### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dd403fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, model, criterion, metric, optimizer):\n",
    "    size = len(data.dataset)\n",
    "    batches = len(data)\n",
    "    running_loss = []\n",
    "    acc = 0.0\n",
    "    correct = 0\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    loss = 0.0\n",
    "    acc = 0.0\n",
    "    current = 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(data,1):\n",
    "        \n",
    "        # forward step\n",
    "        optimizer.zero_grad() # zero out the gradients\n",
    "        y_hat = model(X)  #forward pass\n",
    "        \n",
    "        y = y.unsqueeze(-1) # reduce dimensions of tensor from [256, 1] to [256]\n",
    "        \n",
    "        loss = criterion(y_hat, y)  # calculate loss\n",
    "       \n",
    "        #  backprop step\n",
    "        loss.backward()       # backward pass through model; computes gradients\n",
    "        optimizer.step()      # update weights\n",
    "        \n",
    "        # metrics\n",
    "        y = y.int()\n",
    "        acc = metric(y_hat, y)\n",
    "\n",
    "        y_hat = y_hat.cpu().detach().numpy()\n",
    "        y_hat = y_hat.reshape(-1)\n",
    "        \n",
    "        y = y.cpu().detach().numpy()\n",
    "        y = y.reshape(-1)\n",
    "        \n",
    "        predictions.append(y_hat)\n",
    "        actuals.append(y)\n",
    "            \n",
    "        running_loss.append(loss.item())\n",
    "    \n",
    "        ## every 50 batches, store the results\n",
    "        #if batch % 50 == 0:\n",
    "        #    current = batch * len(X)\n",
    "        \n",
    "    print(f\"\\tTraining\\tAccuracy: {acc:1.10f}\\tLoss: {loss:1.10f}\")\n",
    "    \n",
    "    return predictions, running_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5273a4",
   "metadata": {},
   "source": [
    "#### Testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d07dbf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data, model, criterion, metric):\n",
    "    size = len(data.dataset)\n",
    "    batches = len(data)\n",
    "    tst_loss = 0\n",
    "    correct = 0\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in data:\n",
    "            y_hat = model(X)\n",
    "            y = y.unsqueeze(-1)\n",
    "            tst_loss += criterion(y_hat, y).item()\n",
    "            \n",
    "            y = y.int()\n",
    "            acc = metric(y_hat, y)\n",
    "            #acc = acc.cpu().detach().numpy()\n",
    "            \n",
    "            y_hat = y_hat.cpu().detach().numpy()\n",
    "            y_hat = y_hat.reshape(-1)\n",
    "        \n",
    "            y = y.cpu().detach().numpy()\n",
    "            y = y.reshape(-1)\n",
    "        \n",
    "            predictions.append(y_hat)\n",
    "            actuals.append(y)\n",
    "            \n",
    "    tst_loss /= batches\n",
    "    correct /= size\n",
    "    \n",
    "    print(f\"\\tTest error\\tAccuracy: {acc:1.10f}\\tLoss: {tst_loss:1.10f}\")\n",
    "    return predictions, tst_loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a12ad3",
   "metadata": {},
   "source": [
    "#### Evaluation - train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb53457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(training_data, test_data, model, loss_function, metric, optimizer, epochs, early_stop=True):\n",
    "    training_results = []\n",
    "    training_actuals = []\n",
    "    training_losses = []\n",
    "\n",
    "    testing_results = []\n",
    "    testing_actuals = []\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    # early stop criteria\n",
    "    \n",
    "    default_patience = 3\n",
    "    patience = default_patience\n",
    "    running_loss = []\n",
    "    running_acc = []\n",
    "\n",
    "    for epoch in range(1,epochs+1):\n",
    "        print (f\"Epoch {epoch} / {epochs}\")\n",
    "\n",
    "        trng_result, trng_loss = train(training_data, model, loss_function, metric, optimizer)\n",
    "        tst_result, tst_loss, acc = test(test_data, model, loss_function, metric)\n",
    "        \n",
    "        training_results.append(trng_result)\n",
    "        training_losses.append(trng_loss)\n",
    "        testing_results.append(tst_result)\n",
    "        running_loss.append(tst_loss)\n",
    "        running_acc.append(acc)\n",
    "        \n",
    "        # check for early stop\n",
    "        if epoch > 3:            \n",
    "            if early_stop and ((tst_loss >= running_loss[-2]) or math.isclose(acc,running_acc[-2], abs_tol=1e-8)):\n",
    "                patience = patience - 1\n",
    "            elif early_stop and (tst_loss < running_loss[-2]):\n",
    "                patience = default_patience\n",
    "\n",
    "            if early_stop and (patience <= 0):\n",
    "                print(\"Early stop - \", end=\"\")\n",
    "                break\n",
    "\n",
    "    \n",
    "    print(\"Finished\")\n",
    "    print(\"* \" * 30)\n",
    "    stop = timeit.default_timer()\n",
    "    print(f\"Execution time (in seconds): {stop - start}\")\n",
    "\n",
    "    return training_results, training_losses, testing_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee9a693",
   "metadata": {},
   "source": [
    "#### Multilayer Perception (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd866587",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_size, hidden1=relu, hidden2=relu, hidden3=relu, out_layer=sigmoid):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # construct model dependent on size of inputs\n",
    "        out1_2 = 2*in_size // 3\n",
    "        out2_3 = 2*out1_2 // 3\n",
    "        out3_4 = 2*out2_3 // 3\n",
    "\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(in_size, out1_2),\n",
    "            hidden1,\n",
    "            nn.Linear(out1_2, out2_3),\n",
    "            hidden2,\n",
    "            nn.Linear(out2_3, out3_4),\n",
    "            hidden3,\n",
    "            nn.Linear(out3_4, 1),\n",
    "            out_layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear_stack(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5050abe0",
   "metadata": {},
   "source": [
    "#### Flatten function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "954283c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(thing):\n",
    "    '''\n",
    "    thing: a list\n",
    "    \n",
    "    flatten receives a multi-level list and flatten it down 2 layers\n",
    "    '''\n",
    "    #thing = [element for sublist in thing for element in sublist]\n",
    "    return [element for sublist in thing for element in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fa944e",
   "metadata": {},
   "source": [
    "#### Prepare data for eval and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e211064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(name, training_results, testing_results):\n",
    "    trng_preds = [[] for _ in range(len(training_results))]\n",
    "\n",
    "    tst_preds = [[] for _ in range(len(testing_results))]\n",
    "    \n",
    "    for i in range(len(training_results)):\n",
    "        trng_preds[i] = flatten(training_results[i])\n",
    "\n",
    "        tst_preds[i] = flatten(testing_results[i])\n",
    "\n",
    "    return trng_preds, tst_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1c9839",
   "metadata": {},
   "source": [
    "#### Send results to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a30567c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensorboard(tailend, directory, dataset, train_preds, test_preds, y_train, y_test):\n",
    "    acc_trng_relu = []\n",
    "    acc_tst_relu = []\n",
    "    loss_relu = []\n",
    "\n",
    "    writer = SummaryWriter(log_dir=directory)\n",
    "\n",
    "    for i in range(len(train_preds)):\n",
    "        y_hat = np.array(np.round(train_preds[i]))\n",
    "        y_hat_tst = np.array(np.round(test_preds[i]))\n",
    "        trng_acc = (y_hat == y_train).sum()/len(train_preds[i])\n",
    "        test_acc = (y_hat_tst == y_test).sum()/len(test_preds[i])\n",
    "\n",
    "        avg_loss = np.average(training_losses[i])\n",
    "\n",
    "        acc_trng_relu.append(trng_acc)\n",
    "        acc_tst_relu.append(test_acc)\n",
    "        loss_relu.append(avg_loss)\n",
    "        writer.add_scalar(f\"Training Accuracy {tailend}\", trng_acc, i)\n",
    "        writer.add_scalar(f\"Test Accuracy {tailend}\", test_acc, i)\n",
    "        writer.add_scalar(f\"Training Loss {tailend}\", avg_loss, i)\n",
    "        writer.add_pr_curve(f\"Precision-Recall Curve {tailend}\", y_test, y_hat_tst, i)\n",
    "\n",
    "    t, _ = next(iter(dataset))\n",
    "    writer.add_graph(model, t)\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eef51f5",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10504309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_save(name, data, kind=1):\n",
    "    '''\n",
    "    name : string\n",
    "        designated filename\n",
    "    data : data or pytorch model\n",
    "        the data to save\n",
    "    kind : int\n",
    "        sentinel value - 1 if pytorch model, 0 otherwise\n",
    "    \n",
    "    custom_save stores the data passed into the function into a file with the provided name\n",
    "    '''\n",
    "    \n",
    "    if kind == 1:\n",
    "        ex = \".pth\"\n",
    "    else:\n",
    "        ex = \".parquet\"\n",
    "    \n",
    "    sentinel = True\n",
    "    i = 1\n",
    "\n",
    "    while sentinel:\n",
    "        dirlist = os.listdir()\n",
    "\n",
    "        if name not in dirlist:\n",
    "            if kind == 1:\n",
    "                torch.save(data, name)\n",
    "            else:\n",
    "                data.to_parquet(name)\n",
    "            print(f\"{name} has been saved.\")                \n",
    "            sentinel = False\n",
    "        if name in dirlist:\n",
    "            print(f\"{name} already exists.\", end=\" \")\n",
    "            temp, ext = name.split(ex)\n",
    "            if \"_v\" in temp:\n",
    "                temp, _ = temp.split(\"_v\")\n",
    "            name = f\"{temp}_v{i}{ex}\"\n",
    "            i = i + 1\n",
    "            print(f\"Changing file name to: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8543ae",
   "metadata": {},
   "source": [
    "# Import Data<a id=\"data\"></a>\n",
    "##### COMPAS dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84f4f8b",
   "metadata": {},
   "source": [
    "#### Uncomment next when using google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4288012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_parquet(\"https://github.com/ollin23/bias/blob/main/compas_mk1_v1.parquet?raw=true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5382982d",
   "metadata": {},
   "source": [
    "#### Use the following cell if the data is stored locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "954ed19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(\"compas_mk1_v1.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8795f35",
   "metadata": {},
   "source": [
    "#### Peak the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab028d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6907 entries, 0 to 7213\n",
      "Data columns (total 34 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   age                      6907 non-null   int64  \n",
      " 1   juv_fel_count            6907 non-null   int64  \n",
      " 2   decile_score             6907 non-null   int64  \n",
      " 3   juv_misd_count           6907 non-null   int64  \n",
      " 4   juv_other_count          6907 non-null   int64  \n",
      " 5   priors_count             6907 non-null   int64  \n",
      " 6   days_b_screening_arrest  6907 non-null   float64\n",
      " 7   c_days_from_compas       6907 non-null   float64\n",
      " 8   is_recid                 6907 non-null   int64  \n",
      " 9   is_violent_recid         6907 non-null   int64  \n",
      " 10  decile_score.1           6907 non-null   int64  \n",
      " 11  v_decile_score           6907 non-null   int64  \n",
      " 12  priors_count.1           6907 non-null   int64  \n",
      " 13  start                    6907 non-null   int64  \n",
      " 14  end                      6907 non-null   int64  \n",
      " 15  sex                      6907 non-null   uint8  \n",
      " 16  age_cat_25to45           6907 non-null   uint8  \n",
      " 17  age_cat_over45           6907 non-null   uint8  \n",
      " 18  age_cat_under25          6907 non-null   uint8  \n",
      " 19  race_black               6907 non-null   uint8  \n",
      " 20  race_asian               6907 non-null   uint8  \n",
      " 21  race_white               6907 non-null   uint8  \n",
      " 22  race_hispanic            6907 non-null   uint8  \n",
      " 23  race_native              6907 non-null   uint8  \n",
      " 24  race_Other               6907 non-null   uint8  \n",
      " 25  c_charge_degree          6907 non-null   uint8  \n",
      " 26  score_text_High          6907 non-null   uint8  \n",
      " 27  score_text_Low           6907 non-null   uint8  \n",
      " 28  score_text_Medium        6907 non-null   uint8  \n",
      " 29  v_score_text_High        6907 non-null   uint8  \n",
      " 30  v_score_text_Low         6907 non-null   uint8  \n",
      " 31  v_score_text_Medium      6907 non-null   uint8  \n",
      " 32  event                    6907 non-null   int64  \n",
      " 33  target                   6907 non-null   int64  \n",
      "dtypes: float64(2), int64(15), uint8(17)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a10d91bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6907, 34)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17166be3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat_25to45</th>\n",
       "      <th>age_cat_over45</th>\n",
       "      <th>age_cat_under25</th>\n",
       "      <th>race_black</th>\n",
       "      <th>race_asian</th>\n",
       "      <th>race_white</th>\n",
       "      <th>race_hispanic</th>\n",
       "      <th>race_native</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>score_text_High</th>\n",
       "      <th>score_text_Low</th>\n",
       "      <th>score_text_Medium</th>\n",
       "      <th>v_score_text_High</th>\n",
       "      <th>v_score_text_Low</th>\n",
       "      <th>v_score_text_Medium</th>\n",
       "      <th>event</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>853</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  juv_fel_count  decile_score  juv_misd_count  juv_other_count  \\\n",
       "0   69              0             1               0                0   \n",
       "1   34              0             3               0                0   \n",
       "2   24              0             4               0                1   \n",
       "5   44              0             1               0                0   \n",
       "6   41              0             6               0                0   \n",
       "\n",
       "   priors_count  days_b_screening_arrest  c_days_from_compas  is_recid  \\\n",
       "0             0                     -1.0                 1.0         0   \n",
       "1             0                     -1.0                 1.0         1   \n",
       "2             4                     -1.0                 1.0         1   \n",
       "5             0                      0.0                 0.0         0   \n",
       "6            14                     -1.0                 1.0         1   \n",
       "\n",
       "   is_violent_recid  decile_score.1  v_decile_score  priors_count.1  start  \\\n",
       "0                 0               1               1               0      0   \n",
       "1                 1               3               1               0      9   \n",
       "2                 0               4               3               4      0   \n",
       "5                 0               1               1               0      1   \n",
       "6                 0               6               2              14      5   \n",
       "\n",
       "   end  sex  age_cat_25to45  age_cat_over45  age_cat_under25  race_black  \\\n",
       "0  327    0               0               1                0           0   \n",
       "1  159    0               1               0                0           1   \n",
       "2   63    0               0               0                1           1   \n",
       "5  853    0               1               0                0           0   \n",
       "6   40    0               1               0                0           0   \n",
       "\n",
       "   race_asian  race_white  race_hispanic  race_native  race_Other  \\\n",
       "0           0           0              0            0           1   \n",
       "1           0           0              0            0           0   \n",
       "2           0           0              0            0           0   \n",
       "5           0           0              0            0           1   \n",
       "6           0           1              0            0           0   \n",
       "\n",
       "   c_charge_degree  score_text_High  score_text_Low  score_text_Medium  \\\n",
       "0                1                0               1                  0   \n",
       "1                1                0               1                  0   \n",
       "2                1                0               1                  0   \n",
       "5                0                0               1                  0   \n",
       "6                1                0               0                  1   \n",
       "\n",
       "   v_score_text_High  v_score_text_Low  v_score_text_Medium  event  target  \n",
       "0                  0                 1                    0      0       0  \n",
       "1                  0                 1                    0      1       1  \n",
       "2                  0                 1                    0      0       1  \n",
       "5                  0                 1                    0      0       0  \n",
       "6                  0                 1                    0      1       1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a50e7fb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'juv_fel_count',\n",
       " 'decile_score',\n",
       " 'juv_misd_count',\n",
       " 'juv_other_count',\n",
       " 'priors_count',\n",
       " 'days_b_screening_arrest',\n",
       " 'c_days_from_compas',\n",
       " 'is_recid',\n",
       " 'is_violent_recid',\n",
       " 'decile_score.1',\n",
       " 'v_decile_score',\n",
       " 'priors_count.1',\n",
       " 'start',\n",
       " 'end',\n",
       " 'sex',\n",
       " 'age_cat_25to45',\n",
       " 'age_cat_over45',\n",
       " 'age_cat_under25',\n",
       " 'race_black',\n",
       " 'race_asian',\n",
       " 'race_white',\n",
       " 'race_hispanic',\n",
       " 'race_native',\n",
       " 'race_Other',\n",
       " 'c_charge_degree',\n",
       " 'score_text_High',\n",
       " 'score_text_Low',\n",
       " 'score_text_Medium',\n",
       " 'v_score_text_High',\n",
       " 'v_score_text_Low',\n",
       " 'v_score_text_Medium',\n",
       " 'event',\n",
       " 'target']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6c264c",
   "metadata": {},
   "source": [
    "### Process Data for Neural Net Usage <a id=\"convert\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc92a8e3",
   "metadata": {},
   "source": [
    "#### Split features into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "574fe802",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"target\", axis=1).values.astype(np.float32)\n",
    "y = data.target.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6bf1c7",
   "metadata": {},
   "source": [
    "#### Standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a94a72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaledX = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a40e89",
   "metadata": {},
   "source": [
    "#### Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b312d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaledX, y, test_size=0.3,\n",
    "                                                        random_state=SEED, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53ed4dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4834, 33)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d0aac4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2073, 33)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef745fd",
   "metadata": {},
   "source": [
    "#### Make datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "040aab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train = dataset(X_train, y_train)\n",
    "scaled_test = dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860c0e3",
   "metadata": {},
   "source": [
    "##### Construct test results dataframe for persistent storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "190a7d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(data.drop(\"target\", axis=1).columns)\n",
    "\n",
    "temp = np.round(scaler.inverse_transform(X_test)).astype(int)\n",
    "df = pd.DataFrame(temp, columns=features)\n",
    "df[\"target\"] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1cacf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat_25to45</th>\n",
       "      <th>age_cat_over45</th>\n",
       "      <th>age_cat_under25</th>\n",
       "      <th>race_black</th>\n",
       "      <th>race_asian</th>\n",
       "      <th>race_white</th>\n",
       "      <th>race_hispanic</th>\n",
       "      <th>race_native</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>score_text_High</th>\n",
       "      <th>score_text_Low</th>\n",
       "      <th>score_text_Medium</th>\n",
       "      <th>v_score_text_High</th>\n",
       "      <th>v_score_text_Low</th>\n",
       "      <th>v_score_text_Medium</th>\n",
       "      <th>event</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1171</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  juv_fel_count  decile_score  juv_misd_count  juv_other_count  \\\n",
       "0   25              0             5               0                1   \n",
       "1   35              0             4               0                0   \n",
       "2   32              0             4               0                0   \n",
       "3   20              0            10               0                0   \n",
       "4   50              0             8               0                2   \n",
       "\n",
       "   priors_count  days_b_screening_arrest  c_days_from_compas  is_recid  \\\n",
       "0             4                       -1                   1         1   \n",
       "1             3                       -1                   0         1   \n",
       "2             1                        0                   0         0   \n",
       "3             0                       -1                   1         1   \n",
       "4            24                        0                   1         1   \n",
       "\n",
       "   is_violent_recid  decile_score.1  v_decile_score  priors_count.1  start  \\\n",
       "0                 0               5               4               4     32   \n",
       "1                 0               4               4               3      9   \n",
       "2                 0               4               3               1      0   \n",
       "3                 1              10              10               0      3   \n",
       "4                 1               8               8              24     32   \n",
       "\n",
       "    end  sex  age_cat_25to45  age_cat_over45  age_cat_under25  race_black  \\\n",
       "0   304    0               1               0                0           1   \n",
       "1   462    0               1               0                0           0   \n",
       "2  1171    0               1               0                0           1   \n",
       "3    20    0               0               0                1           1   \n",
       "4    87    0               0               1                0           1   \n",
       "\n",
       "   race_asian  race_white  race_hispanic  race_native  race_Other  \\\n",
       "0           0           0              0            0           0   \n",
       "1           0           1              0            0           0   \n",
       "2           0           0              0            0           0   \n",
       "3           0           0              0            0           0   \n",
       "4           0           0              0            0           0   \n",
       "\n",
       "   c_charge_degree  score_text_High  score_text_Low  score_text_Medium  \\\n",
       "0                1                0               0                  1   \n",
       "1                0                0               1                  0   \n",
       "2                1                0               1                  0   \n",
       "3                0                1               0                  0   \n",
       "4                0                1               0                  0   \n",
       "\n",
       "   v_score_text_High  v_score_text_Low  v_score_text_Medium  event  target  \n",
       "0                  0                 1                    0      1     1.0  \n",
       "1                  0                 1                    0      1     1.0  \n",
       "2                  0                 1                    0      0     0.0  \n",
       "3                  1                 0                    0      1     1.0  \n",
       "4                  1                 0                    0      0     1.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23430d6b",
   "metadata": {},
   "source": [
    "##### Note\n",
    "For this dataset: Female == 1, Male == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28549706",
   "metadata": {},
   "source": [
    "# Experiment Phase 3 - COMPAS Data <a id=\"experiments\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b7fe77",
   "metadata": {},
   "source": [
    "## Trial 3.1 - ReLU (COMPAS) <a id=\"relu\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefc8941",
   "metadata": {},
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af9d93ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"mk2\"\n",
    "directory = f\"COMPAS_{suffix}\"\n",
    "prefix = \"compas\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d3c26",
   "metadata": {},
   "source": [
    "#### Hyperparameters <a id=\"hyperparameters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7aede70",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-5 # 0.00001\n",
    "epochs = 150\n",
    "batches = 100\n",
    "hidden1 = relu\n",
    "hidden2 = relu\n",
    "hidden3 = relu\n",
    "out_layer = sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94eb85f",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68dd22dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to feed data into pytorch neural network, only needs to execute once\n",
    "training_s = DataLoader(scaled_train, batch_size=batches)\n",
    "test_s = DataLoader(scaled_test, batch_size=batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cacc105",
   "metadata": {},
   "source": [
    "#### Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db4bf9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of MLP(\n",
      "  (linear_stack): Sequential(\n",
      "    (0): Linear(in_features=33, out_features=22, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=22, out_features=14, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=14, out_features=9, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=9, out_features=1, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# instantiate model\n",
    "model = MLP(X.shape[1], hidden1, hidden2, hidden3, out_layer).to(device)\n",
    "\n",
    "# select optimizing function\n",
    "optimizer = adam(model.parameters(), lr=alpha)\n",
    "\n",
    "# select loss function\n",
    "loss_function = mse\n",
    "\n",
    "# accuracy metric\n",
    "metric = torchmetrics.functional.accuracy\n",
    "\n",
    "# display model\n",
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dda5258",
   "metadata": {},
   "source": [
    "#### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b3becb2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 150\n",
      "\tTraining\tAccuracy: 0.4117647111\tLoss: 0.2502601743\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2502049201\n",
      "Epoch 2 / 150\n",
      "\tTraining\tAccuracy: 0.4117647111\tLoss: 0.2501519322\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2501047516\n",
      "Epoch 3 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2500397265\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2500037856\n",
      "Epoch 4 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2499230951\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2498992192\n",
      "Epoch 5 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2498037666\n",
      "\tTest error\tAccuracy: 0.4109589159\tLoss: 0.2497923474\n",
      "Epoch 6 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2496735007\n",
      "\tTest error\tAccuracy: 0.4109589159\tLoss: 0.2496847454\n",
      "Epoch 7 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2495396882\n",
      "\tTest error\tAccuracy: 0.4109589159\tLoss: 0.2495722288\n",
      "Epoch 8 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2494028360\n",
      "\tTest error\tAccuracy: 0.4109589159\tLoss: 0.2494553022\n",
      "Epoch 9 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2492670119\n",
      "\tTest error\tAccuracy: 0.4109589159\tLoss: 0.2493356339\n",
      "Epoch 10 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2491272241\n",
      "\tTest error\tAccuracy: 0.4109589159\tLoss: 0.2492112226\n",
      "Epoch 11 / 150\n",
      "\tTraining\tAccuracy: 0.5000000000\tLoss: 0.2489852309\n",
      "\tTest error\tAccuracy: 0.4246575236\tLoss: 0.2490835098\n",
      "Epoch 12 / 150\n",
      "\tTraining\tAccuracy: 0.5000000000\tLoss: 0.2488368601\n",
      "\tTest error\tAccuracy: 0.4246575236\tLoss: 0.2489489501\n",
      "Epoch 13 / 150\n",
      "\tTraining\tAccuracy: 0.5294117928\tLoss: 0.2486731261\n",
      "\tTest error\tAccuracy: 0.4383561611\tLoss: 0.2488123931\n",
      "Epoch 14 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2485005409\n",
      "\tTest error\tAccuracy: 0.4794520438\tLoss: 0.2486683478\n",
      "Epoch 15 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2483211905\n",
      "\tTest error\tAccuracy: 0.5205479264\tLoss: 0.2485222980\n",
      "Epoch 16 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2481400520\n",
      "\tTest error\tAccuracy: 0.5205479264\tLoss: 0.2483675657\n",
      "Epoch 17 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2479582429\n",
      "\tTest error\tAccuracy: 0.5205479264\tLoss: 0.2482070880\n",
      "Epoch 18 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2477750182\n",
      "\tTest error\tAccuracy: 0.5205479264\tLoss: 0.2480408613\n",
      "Epoch 19 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2475801855\n",
      "\tTest error\tAccuracy: 0.5342465639\tLoss: 0.2478688679\n",
      "Epoch 20 / 150\n",
      "\tTraining\tAccuracy: 0.6176470518\tLoss: 0.2473731041\n",
      "\tTest error\tAccuracy: 0.5479452014\tLoss: 0.2476904066\n",
      "Epoch 21 / 150\n",
      "\tTraining\tAccuracy: 0.6176470518\tLoss: 0.2471613884\n",
      "\tTest error\tAccuracy: 0.5890411139\tLoss: 0.2475033041\n",
      "Epoch 22 / 150\n",
      "\tTraining\tAccuracy: 0.6176470518\tLoss: 0.2469444275\n",
      "\tTest error\tAccuracy: 0.6301369667\tLoss: 0.2473093505\n",
      "Epoch 23 / 150\n",
      "\tTraining\tAccuracy: 0.6176470518\tLoss: 0.2467233390\n",
      "\tTest error\tAccuracy: 0.6849315166\tLoss: 0.2471068643\n",
      "Epoch 24 / 150\n",
      "\tTraining\tAccuracy: 0.6470588446\tLoss: 0.2464929521\n",
      "\tTest error\tAccuracy: 0.6849315166\tLoss: 0.2468930107\n",
      "Epoch 25 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2462591827\n",
      "\tTest error\tAccuracy: 0.6712328792\tLoss: 0.2466647568\n",
      "Epoch 26 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2460118234\n",
      "\tTest error\tAccuracy: 0.6986301541\tLoss: 0.2464261921\n",
      "Epoch 27 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2457449287\n",
      "\tTest error\tAccuracy: 0.7123287916\tLoss: 0.2461725736\n",
      "Epoch 28 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2454579920\n",
      "\tTest error\tAccuracy: 0.7808219194\tLoss: 0.2459074734\n",
      "Epoch 29 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2451523840\n",
      "\tTest error\tAccuracy: 0.7945205569\tLoss: 0.2456272259\n",
      "Epoch 30 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2448444963\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.2453331032\n",
      "Epoch 31 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2445363402\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.2450286803\n",
      "Epoch 32 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2442151755\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2447060737\n",
      "Epoch 33 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2438646704\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2443697304\n",
      "Epoch 34 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2435060441\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.2440179757\n",
      "Epoch 35 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2431232482\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2436536572\n",
      "Epoch 36 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2427359223\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.2432792449\n",
      "Epoch 37 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.2423460633\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.2428895412\n",
      "Epoch 38 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.2419379205\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.2424899609\n",
      "Epoch 39 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2415133864\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.2420785157\n",
      "Epoch 40 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.2410639673\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.2416578950\n",
      "Epoch 41 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.2405982912\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.2412238178\n",
      "Epoch 42 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.2401193976\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.2407725432\n",
      "Epoch 43 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.2396303564\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.2403095627\n",
      "Epoch 44 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.2391463965\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.2398419423\n",
      "Epoch 45 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2386451364\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.2393527599\n",
      "Epoch 46 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2381117791\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2388504446\n",
      "Epoch 47 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2375579774\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2383361700\n",
      "Epoch 48 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2369902283\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2378047165\n",
      "Epoch 49 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2363941520\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2372606929\n",
      "Epoch 50 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2357773483\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2367098438\n",
      "Epoch 51 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2351361215\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2361440063\n",
      "Epoch 52 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2344924510\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2355685589\n",
      "Epoch 53 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2338570207\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2349849826\n",
      "Epoch 54 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2332080901\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2343929069\n",
      "Epoch 55 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2325449288\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2337823893\n",
      "Epoch 56 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2318697423\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2331634292\n",
      "Epoch 57 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2311926037\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2325346172\n",
      "Epoch 58 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2305014133\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.2318932599\n",
      "Epoch 59 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2298065126\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2312393458\n",
      "Epoch 60 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2291038930\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2305764996\n",
      "Epoch 61 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2283867747\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2298980235\n",
      "Epoch 62 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2276530564\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2292103909\n",
      "Epoch 63 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2269159704\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2285006082\n",
      "Epoch 64 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2261793762\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2278032587\n",
      "Epoch 65 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2254313529\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2270824753\n",
      "Epoch 66 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2246795595\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2263551106\n",
      "Epoch 67 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2239190042\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2256291062\n",
      "Epoch 68 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2231477946\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2248792166\n",
      "Epoch 69 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2223652154\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2241298606\n",
      "Epoch 70 / 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2215581536\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2233721280\n",
      "Epoch 71 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2207271457\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2225999527\n",
      "Epoch 72 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2198849320\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2218250824\n",
      "Epoch 73 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2190261036\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2210277227\n",
      "Epoch 74 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2181758881\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2202407973\n",
      "Epoch 75 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2173036039\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2194319438\n",
      "Epoch 76 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2164473385\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2186220061\n",
      "Epoch 77 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2155732512\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2177937272\n",
      "Epoch 78 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2147025466\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2169675600\n",
      "Epoch 79 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2137998641\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.2161235433\n",
      "Epoch 80 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2128926069\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2152779457\n",
      "Epoch 81 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2119710892\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2144203065\n",
      "Epoch 82 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2110396773\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2135558845\n",
      "Epoch 83 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2100876123\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2126830717\n",
      "Epoch 84 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2091408074\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2118076420\n",
      "Epoch 85 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2081748843\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2109143202\n",
      "Epoch 86 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2071893364\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2100098552\n",
      "Epoch 87 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2062163055\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2091048019\n",
      "Epoch 88 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2052258402\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2081863972\n",
      "Epoch 89 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2042234391\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2072703711\n",
      "Epoch 90 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2032283098\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2063433996\n",
      "Epoch 91 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2022072077\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2053981984\n",
      "Epoch 92 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2011872679\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2044642426\n",
      "Epoch 93 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.2001767457\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2035230852\n",
      "Epoch 94 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1991408318\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2025720555\n",
      "Epoch 95 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1981226355\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2016265236\n",
      "Epoch 96 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1970826685\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.2006677261\n",
      "Epoch 97 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1960528493\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1997064253\n",
      "Epoch 98 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1950136125\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1987456119\n",
      "Epoch 99 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1939729601\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1977738603\n",
      "Epoch 100 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1929240823\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1968033236\n",
      "Epoch 101 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1918869019\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1958290253\n",
      "Epoch 102 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1908270270\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1948467642\n",
      "Epoch 103 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1897697747\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1938689642\n",
      "Epoch 104 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1887171119\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1928798571\n",
      "Epoch 105 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1876642108\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1918958596\n",
      "Epoch 106 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1866049170\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1909059925\n",
      "Epoch 107 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1855455935\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1899246112\n",
      "Epoch 108 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1844811440\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1889307648\n",
      "Epoch 109 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1834322959\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1879404826\n",
      "Epoch 110 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1823645234\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1869421722\n",
      "Epoch 111 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1813064516\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1859495335\n",
      "Epoch 112 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1802302599\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1849405893\n",
      "Epoch 113 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1791568696\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1839279547\n",
      "Epoch 114 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1780889779\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1829227940\n",
      "Epoch 115 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1770305634\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1819263299\n",
      "Epoch 116 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1759436578\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1809044381\n",
      "Epoch 117 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1748684794\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1798974226\n",
      "Epoch 118 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1737716943\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1788819482\n",
      "Epoch 119 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1726965159\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1778711989\n",
      "Epoch 120 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1716063470\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1768421368\n",
      "Epoch 121 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1705127358\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1758118804\n",
      "Epoch 122 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1694020331\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1747786630\n",
      "Epoch 123 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1683257967\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1737559353\n",
      "Epoch 124 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1672347039\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1727336063\n",
      "Epoch 125 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1661362946\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1716996822\n",
      "Epoch 126 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1650301963\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1706401933\n",
      "Epoch 127 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1639199853\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1696075769\n",
      "Epoch 128 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1628333330\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1685701559\n",
      "Epoch 129 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1617408395\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1675291608\n",
      "Epoch 130 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1606104821\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1664797288\n",
      "Epoch 131 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1595026702\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1654299540\n",
      "Epoch 132 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1583862156\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1643862589\n",
      "Epoch 133 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1572762132\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1633183679\n",
      "Epoch 134 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1561674029\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1622808285\n",
      "Epoch 135 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1550520808\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1612207123\n",
      "Epoch 136 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1539239436\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1601542979\n",
      "Epoch 137 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1528185904\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1590996448\n",
      "Epoch 138 / 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1517109573\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1580459241\n",
      "Epoch 139 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1505869180\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1569961317\n",
      "Epoch 140 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1494455040\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1559153079\n",
      "Epoch 141 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1483201981\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1548478696\n",
      "Epoch 142 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1472127289\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1538040489\n",
      "Epoch 143 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1460873634\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1527424242\n",
      "Epoch 144 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1449512243\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1516672529\n",
      "Epoch 145 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1438183635\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1505941294\n",
      "Epoch 146 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1427012086\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1495349620\n",
      "Epoch 147 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1415864974\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1484651055\n",
      "Epoch 148 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1404181123\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1473721209\n",
      "Epoch 149 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1392991096\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1463199960\n",
      "Epoch 150 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1381637007\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1452454325\n",
      "Finished\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * \n",
      "Execution time (in seconds): 19.080826811026782\n"
     ]
    }
   ],
   "source": [
    "training_results = []\n",
    "training_losses = []\n",
    "testing_results = []\n",
    "\n",
    "training_results, training_losses, testing_results = evaluate(training_s,\n",
    "                                                            test_s,\n",
    "                                                            model,\n",
    "                                                            loss_function,\n",
    "                                                            metric,\n",
    "                                                            optimizer,\n",
    "                                                            epochs,\n",
    "                                                            early_stop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d74917",
   "metadata": {},
   "source": [
    "### Prepare results for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06e25235",
   "metadata": {},
   "outputs": [],
   "source": [
    "tailend = f\"ReLU ({prefix})\"\n",
    "\n",
    "train_preds, test_preds = prep(tailend, training_results, testing_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad279eb",
   "metadata": {},
   "source": [
    "#### Save ReLU Metrics to Tensorboard <a id=\"relu-metrics-for-tensorboard\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7912815",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensorboard(tailend, directory, training_s, train_preds, test_preds, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efce9ecb",
   "metadata": {},
   "source": [
    "#### Add ReLU predictions to persistent storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4472d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compas_relu_mk2.pth has been saved.\n"
     ]
    }
   ],
   "source": [
    "df[\"pred_relu\"] = np.array(np.round(test_preds[-1])).astype(int)\n",
    "\n",
    "name = f\"{prefix}_relu_{suffix}.pth\"\n",
    "custom_save(name, model)\n",
    "#torch.save(model, f\"{prefix}_relu_scaled.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1a2db524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat_25to45</th>\n",
       "      <th>age_cat_over45</th>\n",
       "      <th>age_cat_under25</th>\n",
       "      <th>race_black</th>\n",
       "      <th>race_asian</th>\n",
       "      <th>race_white</th>\n",
       "      <th>race_hispanic</th>\n",
       "      <th>race_native</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>score_text_High</th>\n",
       "      <th>score_text_Low</th>\n",
       "      <th>score_text_Medium</th>\n",
       "      <th>v_score_text_High</th>\n",
       "      <th>v_score_text_Low</th>\n",
       "      <th>v_score_text_Medium</th>\n",
       "      <th>event</th>\n",
       "      <th>target</th>\n",
       "      <th>pred_relu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1171</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  juv_fel_count  decile_score  juv_misd_count  juv_other_count  \\\n",
       "0   25              0             5               0                1   \n",
       "1   35              0             4               0                0   \n",
       "2   32              0             4               0                0   \n",
       "3   20              0            10               0                0   \n",
       "4   50              0             8               0                2   \n",
       "\n",
       "   priors_count  days_b_screening_arrest  c_days_from_compas  is_recid  \\\n",
       "0             4                       -1                   1         1   \n",
       "1             3                       -1                   0         1   \n",
       "2             1                        0                   0         0   \n",
       "3             0                       -1                   1         1   \n",
       "4            24                        0                   1         1   \n",
       "\n",
       "   is_violent_recid  decile_score.1  v_decile_score  priors_count.1  start  \\\n",
       "0                 0               5               4               4     32   \n",
       "1                 0               4               4               3      9   \n",
       "2                 0               4               3               1      0   \n",
       "3                 1              10              10               0      3   \n",
       "4                 1               8               8              24     32   \n",
       "\n",
       "    end  sex  age_cat_25to45  age_cat_over45  age_cat_under25  race_black  \\\n",
       "0   304    0               1               0                0           1   \n",
       "1   462    0               1               0                0           0   \n",
       "2  1171    0               1               0                0           1   \n",
       "3    20    0               0               0                1           1   \n",
       "4    87    0               0               1                0           1   \n",
       "\n",
       "   race_asian  race_white  race_hispanic  race_native  race_Other  \\\n",
       "0           0           0              0            0           0   \n",
       "1           0           1              0            0           0   \n",
       "2           0           0              0            0           0   \n",
       "3           0           0              0            0           0   \n",
       "4           0           0              0            0           0   \n",
       "\n",
       "   c_charge_degree  score_text_High  score_text_Low  score_text_Medium  \\\n",
       "0                1                0               0                  1   \n",
       "1                0                0               1                  0   \n",
       "2                1                0               1                  0   \n",
       "3                0                1               0                  0   \n",
       "4                0                1               0                  0   \n",
       "\n",
       "   v_score_text_High  v_score_text_Low  v_score_text_Medium  event  target  \\\n",
       "0                  0                 1                    0      1     1.0   \n",
       "1                  0                 1                    0      1     1.0   \n",
       "2                  0                 1                    0      0     0.0   \n",
       "3                  1                 0                    0      1     1.0   \n",
       "4                  1                 0                    0      0     1.0   \n",
       "\n",
       "   pred_relu  \n",
       "0          1  \n",
       "1          1  \n",
       "2          0  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811f57a4",
   "metadata": {},
   "source": [
    "## Trial 3.2 - Tanh (COMPAS) <a id=\"tanh\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c858449",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "161ba41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 1e-05\n",
      "epochs: 150\n",
      "batches: 100\n"
     ]
    }
   ],
   "source": [
    "#alpha = 1e-5 # 0.00001\n",
    "#epochs = 50\n",
    "#batches = 256\n",
    "hidden1 = tanh\n",
    "hidden2 = tanh\n",
    "hidden3 = tanh\n",
    "out_layer = sigmoid\n",
    "print(f\"learning rate: {alpha}\")\n",
    "print(f\"epochs: {epochs}\")\n",
    "print(f\"batches: {batches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780c0445",
   "metadata": {},
   "source": [
    "#### Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee868f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of MLP(\n",
      "  (linear_stack): Sequential(\n",
      "    (0): Linear(in_features=33, out_features=22, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=22, out_features=14, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=14, out_features=9, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=9, out_features=1, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# instantiate model\n",
    "model = MLP(X.shape[1], hidden1, hidden2, hidden3, out_layer).to(device)\n",
    "\n",
    "# select optimizing function\n",
    "optimizer = adam(model.parameters(), lr=alpha)\n",
    "\n",
    "# select loss function\n",
    "loss_function = mse\n",
    "\n",
    "# accuracy metric\n",
    "metric = torchmetrics.functional.accuracy\n",
    "\n",
    "# display model\n",
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ca4bc2",
   "metadata": {},
   "source": [
    "#### Training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dece8a90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2516943216\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2471698714\n",
      "Epoch 2 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2505333126\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2460985801\n",
      "Epoch 3 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2493666708\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2450114886\n",
      "Epoch 4 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2481865585\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2439193030\n",
      "Epoch 5 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2469901145\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2428214011\n",
      "Epoch 6 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2457959205\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2417160713\n",
      "Epoch 7 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2445748299\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2405944247\n",
      "Epoch 8 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2433530092\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2394660740\n",
      "Epoch 9 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2421085387\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2383327938\n",
      "Epoch 10 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2408553511\n",
      "\tTest error\tAccuracy: 0.4109589159\tLoss: 0.2371892070\n",
      "Epoch 11 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2395878732\n",
      "\tTest error\tAccuracy: 0.4383561611\tLoss: 0.2360310115\n",
      "Epoch 12 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2383037508\n",
      "\tTest error\tAccuracy: 0.4520547986\tLoss: 0.2348594396\n",
      "Epoch 13 / 150\n",
      "\tTraining\tAccuracy: 0.4705882370\tLoss: 0.2370136827\n",
      "\tTest error\tAccuracy: 0.4520547986\tLoss: 0.2336892542\n",
      "Epoch 14 / 150\n",
      "\tTraining\tAccuracy: 0.4705882370\tLoss: 0.2357012182\n",
      "\tTest error\tAccuracy: 0.4657534361\tLoss: 0.2324892169\n",
      "Epoch 15 / 150\n",
      "\tTraining\tAccuracy: 0.4705882370\tLoss: 0.2343785912\n",
      "\tTest error\tAccuracy: 0.4794520438\tLoss: 0.2312970261\n",
      "Epoch 16 / 150\n",
      "\tTraining\tAccuracy: 0.5000000000\tLoss: 0.2330315560\n",
      "\tTest error\tAccuracy: 0.5068492889\tLoss: 0.2300677541\n",
      "Epoch 17 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2316815853\n",
      "\tTest error\tAccuracy: 0.5479452014\tLoss: 0.2288517810\n",
      "Epoch 18 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2303112596\n",
      "\tTest error\tAccuracy: 0.5479452014\tLoss: 0.2276111728\n",
      "Epoch 19 / 150\n",
      "\tTraining\tAccuracy: 0.5588235259\tLoss: 0.2289210707\n",
      "\tTest error\tAccuracy: 0.5479452014\tLoss: 0.2263504309\n",
      "Epoch 20 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2275219113\n",
      "\tTest error\tAccuracy: 0.5753424764\tLoss: 0.2250902695\n",
      "Epoch 21 / 150\n",
      "\tTraining\tAccuracy: 0.6470588446\tLoss: 0.2261169851\n",
      "\tTest error\tAccuracy: 0.5890411139\tLoss: 0.2238145861\n",
      "Epoch 22 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2246870995\n",
      "\tTest error\tAccuracy: 0.6438356042\tLoss: 0.2225193119\n",
      "Epoch 23 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2232452333\n",
      "\tTest error\tAccuracy: 0.6438356042\tLoss: 0.2212277715\n",
      "Epoch 24 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2217863947\n",
      "\tTest error\tAccuracy: 0.6438356042\tLoss: 0.2199072511\n",
      "Epoch 25 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2203322053\n",
      "\tTest error\tAccuracy: 0.6575342417\tLoss: 0.2185975185\n",
      "Epoch 26 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2188325524\n",
      "\tTest error\tAccuracy: 0.6575342417\tLoss: 0.2172596646\n",
      "Epoch 27 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2173377872\n",
      "\tTest error\tAccuracy: 0.6712328792\tLoss: 0.2159125117\n",
      "Epoch 28 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2158502489\n",
      "\tTest error\tAccuracy: 0.6986301541\tLoss: 0.2145659569\n",
      "Epoch 29 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2143311203\n",
      "\tTest error\tAccuracy: 0.7123287916\tLoss: 0.2131939112\n",
      "Epoch 30 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2127962708\n",
      "\tTest error\tAccuracy: 0.7534246445\tLoss: 0.2118229575\n",
      "Epoch 31 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2112543732\n",
      "\tTest error\tAccuracy: 0.7808219194\tLoss: 0.2104492393\n",
      "Epoch 32 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2097188383\n",
      "\tTest error\tAccuracy: 0.7808219194\tLoss: 0.2090600913\n",
      "Epoch 33 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2081687301\n",
      "\tTest error\tAccuracy: 0.7945205569\tLoss: 0.2076689232\n",
      "Epoch 34 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2066075951\n",
      "\tTest error\tAccuracy: 0.7945205569\tLoss: 0.2062686242\n",
      "Epoch 35 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2050200403\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.2048506098\n",
      "Epoch 36 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2034675032\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.2034500660\n",
      "Epoch 37 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2018805742\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.2020274642\n",
      "Epoch 38 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2002862990\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.2006057636\n",
      "Epoch 39 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1987062395\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.1991814744\n",
      "Epoch 40 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1971171200\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.1977680865\n",
      "Epoch 41 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1955143362\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.1963275813\n",
      "Epoch 42 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1939136684\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.1948950830\n",
      "Epoch 43 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1923103631\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.1934589701\n",
      "Epoch 44 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1907071322\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.1920187750\n",
      "Epoch 45 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1890986413\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1905812685\n",
      "Epoch 46 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1874848902\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1891328600\n",
      "Epoch 47 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1858916432\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1876913451\n",
      "Epoch 48 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1842827648\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1862529765\n",
      "Epoch 49 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1826842576\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1848156246\n",
      "Epoch 50 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1810582429\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1833508802\n",
      "Epoch 51 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1794783026\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1819177965\n",
      "Epoch 52 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1778749377\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1804764810\n",
      "Epoch 53 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1762624979\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1790268166\n",
      "Epoch 54 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1746828109\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1776003312\n",
      "Epoch 55 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1730737537\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1761405227\n",
      "Epoch 56 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1714790761\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1747065577\n",
      "Epoch 57 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1698986292\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1732751316\n",
      "Epoch 58 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1682812721\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1718147184\n",
      "Epoch 59 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1667127907\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1703839621\n",
      "Epoch 60 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1651204079\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1689446072\n",
      "Epoch 61 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1635453552\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1675090996\n",
      "Epoch 62 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1619404703\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1660447248\n",
      "Epoch 63 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1603618860\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1646011018\n",
      "Epoch 64 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1587744653\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1631601410\n",
      "Epoch 65 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1572040915\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1617160454\n",
      "Epoch 66 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1556067467\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1602719114\n",
      "Epoch 67 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1540385932\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1588379570\n",
      "Epoch 68 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1524597108\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1573897565\n",
      "Epoch 69 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1508987099\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1559555197\n",
      "Epoch 70 / 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1493134201\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1545055927\n",
      "Epoch 71 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1477558613\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1530675704\n",
      "Epoch 72 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1461754590\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1516236918\n",
      "Epoch 73 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1446318328\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1501869687\n",
      "Epoch 74 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1430760026\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1487505436\n",
      "Epoch 75 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1415139884\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1473044256\n",
      "Epoch 76 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1399683207\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1458783902\n",
      "Epoch 77 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1384368241\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1444598749\n",
      "Epoch 78 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1368908882\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1430271392\n",
      "Epoch 79 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1353799254\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1416081201\n",
      "Epoch 80 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1338406503\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1401792059\n",
      "Epoch 81 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1323204041\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1387626160\n",
      "Epoch 82 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1307992488\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1373323837\n",
      "Epoch 83 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1292954683\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1359308962\n",
      "Epoch 84 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1278165728\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1345256198\n",
      "Epoch 85 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1263203174\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1331268141\n",
      "Epoch 86 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1248424724\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1317391147\n",
      "Epoch 87 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1233888268\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1303661650\n",
      "Epoch 88 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1219191998\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1289673263\n",
      "Epoch 89 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1204595417\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1275993210\n",
      "Epoch 90 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1190236583\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1262378047\n",
      "Epoch 91 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1175868064\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1248667645\n",
      "Epoch 92 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1161781624\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1235248234\n",
      "Epoch 93 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1147740483\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1221704036\n",
      "Epoch 94 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1133831814\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1208475207\n",
      "Epoch 95 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1120114177\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1195364098\n",
      "Epoch 96 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1106491834\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1182227834\n",
      "Epoch 97 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1092922688\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1169187682\n",
      "Epoch 98 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1079539582\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1156265207\n",
      "Epoch 99 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1066185310\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1143355536\n",
      "Epoch 100 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1053044125\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1130506258\n",
      "Epoch 101 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1039924398\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1117858773\n",
      "Epoch 102 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1027153060\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1105389152\n",
      "Epoch 103 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1014318019\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1092989565\n",
      "Epoch 104 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1001891941\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1080693695\n",
      "Epoch 105 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0989457592\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1068632134\n",
      "Epoch 106 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0977302715\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1056579646\n",
      "Epoch 107 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0965086147\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1044687891\n",
      "Epoch 108 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0953114703\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1032836909\n",
      "Epoch 109 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0941275284\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1021053092\n",
      "Epoch 110 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0929622874\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1009614549\n",
      "Epoch 111 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0918017700\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0998092205\n",
      "Epoch 112 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0906624123\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0986692121\n",
      "Epoch 113 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0895312652\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0975517063\n",
      "Epoch 114 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0884366706\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0964537941\n",
      "Epoch 115 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0873402655\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0953592665\n",
      "Epoch 116 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0862609744\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0942696333\n",
      "Epoch 117 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0851926059\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0932060104\n",
      "Epoch 118 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0841618702\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0921555797\n",
      "Epoch 119 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0831410587\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0911259814\n",
      "Epoch 120 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0821179226\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0900889436\n",
      "Epoch 121 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0811152905\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0890768507\n",
      "Epoch 122 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0801359043\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0880806755\n",
      "Epoch 123 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0791600570\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0870952996\n",
      "Epoch 124 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0782141164\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0861183196\n",
      "Epoch 125 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0772627071\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0851605960\n",
      "Epoch 126 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0763505772\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0842131582\n",
      "Epoch 127 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0754479542\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0832777502\n",
      "Epoch 128 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0745475665\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0823641352\n",
      "Epoch 129 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0736598298\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0814581120\n",
      "Epoch 130 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0727921501\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0805569213\n",
      "Epoch 131 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0719393864\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0796807391\n",
      "Epoch 132 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0711082295\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0788128319\n",
      "Epoch 133 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0703020617\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0779609091\n",
      "Epoch 134 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0694876909\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0771326721\n",
      "Epoch 135 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0687016845\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0762937959\n",
      "Epoch 136 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0679065213\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0754853317\n",
      "Epoch 137 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0671255514\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0746669141\n",
      "Epoch 138 / 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0663761869\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0738699298\n",
      "Epoch 139 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0656458959\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0731073171\n",
      "Epoch 140 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0649189129\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0723493521\n",
      "Epoch 141 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0641931072\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0715801684\n",
      "Epoch 142 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0634836629\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0708324232\n",
      "Epoch 143 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0627916157\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0701053164\n",
      "Epoch 144 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0621101297\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0693844832\n",
      "Epoch 145 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0614408478\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0686699132\n",
      "Epoch 146 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0607933439\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0679809955\n",
      "Epoch 147 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0601617172\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0672958424\n",
      "Epoch 148 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0595248230\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0666247372\n",
      "Epoch 149 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0588969216\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0659512216\n",
      "Epoch 150 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0582746826\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0652969496\n",
      "Finished\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * \n",
      "Execution time (in seconds): 19.17428351507988\n"
     ]
    }
   ],
   "source": [
    "training_results = []\n",
    "training_losses = []\n",
    "testing_results = []\n",
    "\n",
    "training_results, training_losses, testing_results = evaluate(training_s,\n",
    "                                                            test_s,\n",
    "                                                            model,\n",
    "                                                            loss_function,\n",
    "                                                            metric,\n",
    "                                                            optimizer,\n",
    "                                                            epochs,\n",
    "                                                            early_stop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57043a04",
   "metadata": {},
   "source": [
    "#### Prepare tanh results for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3cf086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tailend = f\"Tanh ({prefix})\"\n",
    "\n",
    "train_preds, test_preds = prep(tailend, training_results, testing_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fbb7ed",
   "metadata": {},
   "source": [
    "#### Generate tensorboard summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5baf5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensorboard(tailend, directory, training_s, train_preds, test_preds, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd1d008",
   "metadata": {},
   "source": [
    "#### Store Tanh results in dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd2c0185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compas_tanh_mk2.pth has been saved.\n"
     ]
    }
   ],
   "source": [
    "df[\"pred_tanh\"] = np.array(np.round(test_preds[-1])).astype(int)\n",
    "name = f\"{prefix}_tanh_{suffix}.pth\"\n",
    "custom_save(name, model)\n",
    "#torch.save(model, f\"{prefix}_tanh_scaled.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20bc6f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat_25to45</th>\n",
       "      <th>age_cat_over45</th>\n",
       "      <th>age_cat_under25</th>\n",
       "      <th>race_black</th>\n",
       "      <th>race_asian</th>\n",
       "      <th>race_white</th>\n",
       "      <th>race_hispanic</th>\n",
       "      <th>race_native</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>score_text_High</th>\n",
       "      <th>score_text_Low</th>\n",
       "      <th>score_text_Medium</th>\n",
       "      <th>v_score_text_High</th>\n",
       "      <th>v_score_text_Low</th>\n",
       "      <th>v_score_text_Medium</th>\n",
       "      <th>event</th>\n",
       "      <th>target</th>\n",
       "      <th>pred_relu</th>\n",
       "      <th>pred_tanh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1171</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  juv_fel_count  decile_score  juv_misd_count  juv_other_count  \\\n",
       "0   25              0             5               0                1   \n",
       "1   35              0             4               0                0   \n",
       "2   32              0             4               0                0   \n",
       "3   20              0            10               0                0   \n",
       "4   50              0             8               0                2   \n",
       "\n",
       "   priors_count  days_b_screening_arrest  c_days_from_compas  is_recid  \\\n",
       "0             4                       -1                   1         1   \n",
       "1             3                       -1                   0         1   \n",
       "2             1                        0                   0         0   \n",
       "3             0                       -1                   1         1   \n",
       "4            24                        0                   1         1   \n",
       "\n",
       "   is_violent_recid  decile_score.1  v_decile_score  priors_count.1  start  \\\n",
       "0                 0               5               4               4     32   \n",
       "1                 0               4               4               3      9   \n",
       "2                 0               4               3               1      0   \n",
       "3                 1              10              10               0      3   \n",
       "4                 1               8               8              24     32   \n",
       "\n",
       "    end  sex  age_cat_25to45  age_cat_over45  age_cat_under25  race_black  \\\n",
       "0   304    0               1               0                0           1   \n",
       "1   462    0               1               0                0           0   \n",
       "2  1171    0               1               0                0           1   \n",
       "3    20    0               0               0                1           1   \n",
       "4    87    0               0               1                0           1   \n",
       "\n",
       "   race_asian  race_white  race_hispanic  race_native  race_Other  \\\n",
       "0           0           0              0            0           0   \n",
       "1           0           1              0            0           0   \n",
       "2           0           0              0            0           0   \n",
       "3           0           0              0            0           0   \n",
       "4           0           0              0            0           0   \n",
       "\n",
       "   c_charge_degree  score_text_High  score_text_Low  score_text_Medium  \\\n",
       "0                1                0               0                  1   \n",
       "1                0                0               1                  0   \n",
       "2                1                0               1                  0   \n",
       "3                0                1               0                  0   \n",
       "4                0                1               0                  0   \n",
       "\n",
       "   v_score_text_High  v_score_text_Low  v_score_text_Medium  event  target  \\\n",
       "0                  0                 1                    0      1     1.0   \n",
       "1                  0                 1                    0      1     1.0   \n",
       "2                  0                 1                    0      0     0.0   \n",
       "3                  1                 0                    0      1     1.0   \n",
       "4                  1                 0                    0      0     1.0   \n",
       "\n",
       "   pred_relu  pred_tanh  \n",
       "0          1          1  \n",
       "1          1          1  \n",
       "2          0          0  \n",
       "3          1          1  \n",
       "4          1          1  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dd5871",
   "metadata": {},
   "source": [
    "## Trial 3.3 - ELU (COMPAS)<a id=\"elu\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1f8673",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7907eaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 1e-05\n",
      "epochs: 150\n",
      "batches: 100\n"
     ]
    }
   ],
   "source": [
    "#alpha = 1e-5 # 0.00001\n",
    "#epochs = 50\n",
    "#batches = 256\n",
    "hidden1 = elu\n",
    "hidden2 = elu\n",
    "hidden3 = elu\n",
    "out_layer = sigmoid\n",
    "print(f\"learning rate: {alpha}\")\n",
    "print(f\"epochs: {epochs}\")\n",
    "print(f\"batches: {batches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79df8ba0",
   "metadata": {},
   "source": [
    "#### Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f411ba08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of MLP(\n",
      "  (linear_stack): Sequential(\n",
      "    (0): Linear(in_features=33, out_features=22, bias=True)\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): Linear(in_features=22, out_features=14, bias=True)\n",
      "    (3): ELU(alpha=1.0)\n",
      "    (4): Linear(in_features=14, out_features=9, bias=True)\n",
      "    (5): ELU(alpha=1.0)\n",
      "    (6): Linear(in_features=9, out_features=1, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# instantiate model\n",
    "model = MLP(X.shape[1], hidden1, hidden2, hidden3, out_layer).to(device)\n",
    "\n",
    "# select optimizing function\n",
    "optimizer = adam(model.parameters(), lr=alpha)\n",
    "\n",
    "# select loss function\n",
    "criterion = mse\n",
    "\n",
    "# accuracy metric\n",
    "metric = torchmetrics.functional.accuracy\n",
    "\n",
    "# display model\n",
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91ba9ad",
   "metadata": {},
   "source": [
    "#### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b75c1dfd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2526420057\n",
      "\tTest error\tAccuracy: 0.3150684834\tLoss: 0.2532411019\n",
      "Epoch 2 / 150\n",
      "\tTraining\tAccuracy: 0.4705882370\tLoss: 0.2519218028\n",
      "\tTest error\tAccuracy: 0.3561643958\tLoss: 0.2525221010\n",
      "Epoch 3 / 150\n",
      "\tTraining\tAccuracy: 0.4705882370\tLoss: 0.2511947453\n",
      "\tTest error\tAccuracy: 0.3835616410\tLoss: 0.2518041992\n",
      "Epoch 4 / 150\n",
      "\tTraining\tAccuracy: 0.5000000000\tLoss: 0.2504802644\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2510956022\n",
      "Epoch 5 / 150\n",
      "\tTraining\tAccuracy: 0.5000000000\tLoss: 0.2497570366\n",
      "\tTest error\tAccuracy: 0.4109589159\tLoss: 0.2503848005\n",
      "Epoch 6 / 150\n",
      "\tTraining\tAccuracy: 0.5000000000\tLoss: 0.2490449250\n",
      "\tTest error\tAccuracy: 0.4657534361\tLoss: 0.2496732757\n",
      "Epoch 7 / 150\n",
      "\tTraining\tAccuracy: 0.5294117928\tLoss: 0.2483220994\n",
      "\tTest error\tAccuracy: 0.4657534361\tLoss: 0.2489615757\n",
      "Epoch 8 / 150\n",
      "\tTraining\tAccuracy: 0.6176470518\tLoss: 0.2475927025\n",
      "\tTest error\tAccuracy: 0.5068492889\tLoss: 0.2482390226\n",
      "Epoch 9 / 150\n",
      "\tTraining\tAccuracy: 0.6176470518\tLoss: 0.2468550652\n",
      "\tTest error\tAccuracy: 0.5342465639\tLoss: 0.2475066973\n",
      "Epoch 10 / 150\n",
      "\tTraining\tAccuracy: 0.6176470518\tLoss: 0.2461120635\n",
      "\tTest error\tAccuracy: 0.5479452014\tLoss: 0.2467735055\n",
      "Epoch 11 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2453552932\n",
      "\tTest error\tAccuracy: 0.5890411139\tLoss: 0.2460246249\n",
      "Epoch 12 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2445831299\n",
      "\tTest error\tAccuracy: 0.6027397513\tLoss: 0.2452585477\n",
      "Epoch 13 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2437980920\n",
      "\tTest error\tAccuracy: 0.6438356042\tLoss: 0.2444883784\n",
      "Epoch 14 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2430001646\n",
      "\tTest error\tAccuracy: 0.6438356042\tLoss: 0.2437006384\n",
      "Epoch 15 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2421816736\n",
      "\tTest error\tAccuracy: 0.6575342417\tLoss: 0.2428962510\n",
      "Epoch 16 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2413518280\n",
      "\tTest error\tAccuracy: 0.6849315166\tLoss: 0.2420769320\n",
      "Epoch 17 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2404964119\n",
      "\tTest error\tAccuracy: 0.6986301541\tLoss: 0.2412378802\n",
      "Epoch 18 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2396289259\n",
      "\tTest error\tAccuracy: 0.7123287916\tLoss: 0.2403818490\n",
      "Epoch 19 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2387356460\n",
      "\tTest error\tAccuracy: 0.7123287916\tLoss: 0.2395078746\n",
      "Epoch 20 / 150\n",
      "\tTraining\tAccuracy: 0.7352941036\tLoss: 0.2378300577\n",
      "\tTest error\tAccuracy: 0.7123287916\tLoss: 0.2386177487\n",
      "Epoch 21 / 150\n",
      "\tTraining\tAccuracy: 0.7352941036\tLoss: 0.2368961573\n",
      "\tTest error\tAccuracy: 0.7123287916\tLoss: 0.2377083940\n",
      "Epoch 22 / 150\n",
      "\tTraining\tAccuracy: 0.7352941036\tLoss: 0.2359498292\n",
      "\tTest error\tAccuracy: 0.7123287916\tLoss: 0.2367762519\n",
      "Epoch 23 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2349661142\n",
      "\tTest error\tAccuracy: 0.7123287916\tLoss: 0.2358240734\n",
      "Epoch 24 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2339775711\n",
      "\tTest error\tAccuracy: 0.7123287916\tLoss: 0.2348496091\n",
      "Epoch 25 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2329621613\n",
      "\tTest error\tAccuracy: 0.7260273695\tLoss: 0.2338724541\n",
      "Epoch 26 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2319154441\n",
      "\tTest error\tAccuracy: 0.7260273695\tLoss: 0.2328578340\n",
      "Epoch 27 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2308639884\n",
      "\tTest error\tAccuracy: 0.7260273695\tLoss: 0.2318329031\n",
      "Epoch 28 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2297767997\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2307772729\n",
      "Epoch 29 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2286534160\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2296961574\n",
      "Epoch 30 / 150\n",
      "\tTraining\tAccuracy: 0.7352941036\tLoss: 0.2275367975\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2286227324\n",
      "Epoch 31 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2263826579\n",
      "\tTest error\tAccuracy: 0.7534246445\tLoss: 0.2275050985\n",
      "Epoch 32 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2252245694\n",
      "\tTest error\tAccuracy: 0.7808219194\tLoss: 0.2263866400\n",
      "Epoch 33 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2240241915\n",
      "\tTest error\tAccuracy: 0.7808219194\tLoss: 0.2252347405\n",
      "Epoch 34 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2228034288\n",
      "\tTest error\tAccuracy: 0.7808219194\tLoss: 0.2240579951\n",
      "Epoch 35 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2215802521\n",
      "\tTest error\tAccuracy: 0.7945205569\tLoss: 0.2228788854\n",
      "Epoch 36 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2203159332\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.2216681057\n",
      "Epoch 37 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2190420181\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.2204430231\n",
      "Epoch 38 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2177577913\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.2192078573\n",
      "Epoch 39 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2164502442\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.2179490186\n",
      "Epoch 40 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2151267976\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2166808468\n",
      "Epoch 41 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2137718648\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2153802755\n",
      "Epoch 42 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2124068290\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2140771413\n",
      "Epoch 43 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2110394239\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2127616093\n",
      "Epoch 44 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2096435577\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2114299770\n",
      "Epoch 45 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2082494646\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2100857681\n",
      "Epoch 46 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2068205625\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2087320685\n",
      "Epoch 47 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2053854316\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2073583411\n",
      "Epoch 48 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2039532959\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2059896993\n",
      "Epoch 49 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2024817467\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2045908861\n",
      "Epoch 50 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2010374963\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2032176866\n",
      "Epoch 51 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1995466501\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.2018110404\n",
      "Epoch 52 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1980685741\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.2004016120\n",
      "Epoch 53 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1965694427\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.1989931571\n",
      "Epoch 54 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1950818896\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.1975799693\n",
      "Epoch 55 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1935870200\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1961667914\n",
      "Epoch 56 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1920637041\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1947316116\n",
      "Epoch 57 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1905634850\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.1933116934\n",
      "Epoch 58 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1890456527\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1918841976\n",
      "Epoch 59 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1875302941\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1904589406\n",
      "Epoch 60 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1860291958\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1890584316\n",
      "Epoch 61 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1845016479\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1876219334\n",
      "Epoch 62 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1829970628\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1862175472\n",
      "Epoch 63 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1814667284\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1847779623\n",
      "Epoch 64 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1799572259\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1833677051\n",
      "Epoch 65 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1784228235\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1819414858\n",
      "Epoch 66 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1769092083\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1805256371\n",
      "Epoch 67 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1754113585\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1791355383\n",
      "Epoch 68 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1738897711\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.1777136326\n",
      "Epoch 69 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1723849624\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1763104704\n",
      "Epoch 70 / 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1708803773\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1749165278\n",
      "Epoch 71 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1693591326\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1735014447\n",
      "Epoch 72 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1678642780\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1721147199\n",
      "Epoch 73 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1663591862\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1707311989\n",
      "Epoch 74 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1648470759\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1693159760\n",
      "Epoch 75 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1633389741\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1679333079\n",
      "Epoch 76 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.1618376672\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1665542026\n",
      "Epoch 77 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1603398025\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1651600777\n",
      "Epoch 78 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1588321626\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1637631527\n",
      "Epoch 79 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1573296934\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1623844504\n",
      "Epoch 80 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1558217406\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1610011969\n",
      "Epoch 81 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1543232650\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1596131190\n",
      "Epoch 82 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1528203636\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1582328968\n",
      "Epoch 83 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1512930542\n",
      "\tTest error\tAccuracy: 0.8904109597\tLoss: 0.1568239211\n",
      "Epoch 84 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1498011947\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1554503334\n",
      "Epoch 85 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1482886821\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1540640564\n",
      "Epoch 86 / 150\n",
      "\tTraining\tAccuracy: 0.8823529482\tLoss: 0.1467693150\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1526695043\n",
      "Epoch 87 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1452574730\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1512791954\n",
      "Epoch 88 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1437202245\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1498696130\n",
      "Epoch 89 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1422160119\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1484811796\n",
      "Epoch 90 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1406788528\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1470797871\n",
      "Epoch 91 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1391613334\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1456884302\n",
      "Epoch 92 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1376227885\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1442779757\n",
      "Epoch 93 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1360916793\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1428614429\n",
      "Epoch 94 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1345442086\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1414460827\n",
      "Epoch 95 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1330024302\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1400468300\n",
      "Epoch 96 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1314773858\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1386441187\n",
      "Epoch 97 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1299161613\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1372152737\n",
      "Epoch 98 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1283735633\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1358230831\n",
      "Epoch 99 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1268388182\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1344135492\n",
      "Epoch 100 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1252922416\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1330030082\n",
      "Epoch 101 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1237693503\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1316008955\n",
      "Epoch 102 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1222205013\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1301676691\n",
      "Epoch 103 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1206749901\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1287618471\n",
      "Epoch 104 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1191379726\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1273382796\n",
      "Epoch 105 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1176135540\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1259360044\n",
      "Epoch 106 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1160933450\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1245265220\n",
      "Epoch 107 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1145650297\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1231125157\n",
      "Epoch 108 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1130543202\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1217166643\n",
      "Epoch 109 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1115425229\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1203104914\n",
      "Epoch 110 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1100415662\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1189237319\n",
      "Epoch 111 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1085471138\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1175342752\n",
      "Epoch 112 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1070740074\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1161585503\n",
      "Epoch 113 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1055980697\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1147649600\n",
      "Epoch 114 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1041374356\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1134052819\n",
      "Epoch 115 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1026788056\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1120430196\n",
      "Epoch 116 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.1012310013\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1106841610\n",
      "Epoch 117 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0998034552\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1093232195\n",
      "Epoch 118 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0983812287\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1079922347\n",
      "Epoch 119 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0969709978\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1066560834\n",
      "Epoch 120 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0955782160\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1053315036\n",
      "Epoch 121 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0941882133\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1040036331\n",
      "Epoch 122 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0928180069\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1027080935\n",
      "Epoch 123 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0914724171\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1014067311\n",
      "Epoch 124 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0901082382\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1001220931\n",
      "Epoch 125 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0887821019\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.0988494580\n",
      "Epoch 126 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0874790847\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.0976006605\n",
      "Epoch 127 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0861879066\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.0963614278\n",
      "Epoch 128 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0849084556\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.0951087957\n",
      "Epoch 129 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0836362839\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0938870627\n",
      "Epoch 130 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0824101344\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0926811574\n",
      "Epoch 131 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0811726749\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0915033690\n",
      "Epoch 132 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0799576417\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0903147165\n",
      "Epoch 133 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0787694752\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0891510021\n",
      "Epoch 134 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0775821656\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0879967894\n",
      "Epoch 135 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0764245689\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0868519289\n",
      "Epoch 136 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0752951652\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0857308312\n",
      "Epoch 137 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0741681606\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0846244214\n",
      "Epoch 138 / 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0730753541\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0835473552\n",
      "Epoch 139 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0719746724\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0824641259\n",
      "Epoch 140 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0709027573\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0813964403\n",
      "Epoch 141 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0698432326\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0803494510\n",
      "Epoch 142 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0688063353\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0793072996\n",
      "Epoch 143 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0677824616\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0782870232\n",
      "Epoch 144 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0667916983\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0772899646\n",
      "Epoch 145 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0658110082\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0762980829\n",
      "Epoch 146 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0648494735\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0753327924\n",
      "Epoch 147 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0638955012\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0743764791\n",
      "Epoch 148 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0629709363\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0734377709\n",
      "Epoch 149 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0620501749\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0725008059\n",
      "Epoch 150 / 150\n",
      "\tTraining\tAccuracy: 0.9705882072\tLoss: 0.0611527450\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.0715934223\n",
      "Finished\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * \n",
      "Execution time (in seconds): 19.57205408194568\n"
     ]
    }
   ],
   "source": [
    "training_results = []\n",
    "training_losses = []\n",
    "testing_results = []\n",
    "\n",
    "training_results, training_losses, testing_results = evaluate(training_s,\n",
    "                                                            test_s,\n",
    "                                                            model,\n",
    "                                                            loss_function,\n",
    "                                                            metric,\n",
    "                                                            optimizer,\n",
    "                                                            epochs,\n",
    "                                                            early_stop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ff80b",
   "metadata": {},
   "source": [
    "#### Prepare ELU results for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e93287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tailend = f\"ELU ({prefix})\"\n",
    "\n",
    "train_preds, test_preds = prep(tailend, training_results, testing_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fb14be",
   "metadata": {},
   "source": [
    "#### Save metrics to tensorboad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "18bbfa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensorboard(tailend, directory, training_s, train_preds, test_preds, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477d283c",
   "metadata": {},
   "source": [
    "#### Add ELU test results to persistent storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f44fd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compas_elu_mk2.pth has been saved.\n"
     ]
    }
   ],
   "source": [
    "df[\"pred_elu\"] = np.array(np.round(test_preds[-1])).astype(int)\n",
    "name = f\"{prefix}_elu_{suffix}.pth\"\n",
    "custom_save(name, model, 1)\n",
    "#torch.save(model, f\"{prefix}_elu_scaled.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cb977740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat_25to45</th>\n",
       "      <th>age_cat_over45</th>\n",
       "      <th>age_cat_under25</th>\n",
       "      <th>race_black</th>\n",
       "      <th>race_asian</th>\n",
       "      <th>race_white</th>\n",
       "      <th>race_hispanic</th>\n",
       "      <th>race_native</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>score_text_High</th>\n",
       "      <th>score_text_Low</th>\n",
       "      <th>score_text_Medium</th>\n",
       "      <th>v_score_text_High</th>\n",
       "      <th>v_score_text_Low</th>\n",
       "      <th>v_score_text_Medium</th>\n",
       "      <th>event</th>\n",
       "      <th>target</th>\n",
       "      <th>pred_relu</th>\n",
       "      <th>pred_tanh</th>\n",
       "      <th>pred_elu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1171</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  juv_fel_count  decile_score  juv_misd_count  juv_other_count  \\\n",
       "0   25              0             5               0                1   \n",
       "1   35              0             4               0                0   \n",
       "2   32              0             4               0                0   \n",
       "3   20              0            10               0                0   \n",
       "4   50              0             8               0                2   \n",
       "\n",
       "   priors_count  days_b_screening_arrest  c_days_from_compas  is_recid  \\\n",
       "0             4                       -1                   1         1   \n",
       "1             3                       -1                   0         1   \n",
       "2             1                        0                   0         0   \n",
       "3             0                       -1                   1         1   \n",
       "4            24                        0                   1         1   \n",
       "\n",
       "   is_violent_recid  decile_score.1  v_decile_score  priors_count.1  start  \\\n",
       "0                 0               5               4               4     32   \n",
       "1                 0               4               4               3      9   \n",
       "2                 0               4               3               1      0   \n",
       "3                 1              10              10               0      3   \n",
       "4                 1               8               8              24     32   \n",
       "\n",
       "    end  sex  age_cat_25to45  age_cat_over45  age_cat_under25  race_black  \\\n",
       "0   304    0               1               0                0           1   \n",
       "1   462    0               1               0                0           0   \n",
       "2  1171    0               1               0                0           1   \n",
       "3    20    0               0               0                1           1   \n",
       "4    87    0               0               1                0           1   \n",
       "\n",
       "   race_asian  race_white  race_hispanic  race_native  race_Other  \\\n",
       "0           0           0              0            0           0   \n",
       "1           0           1              0            0           0   \n",
       "2           0           0              0            0           0   \n",
       "3           0           0              0            0           0   \n",
       "4           0           0              0            0           0   \n",
       "\n",
       "   c_charge_degree  score_text_High  score_text_Low  score_text_Medium  \\\n",
       "0                1                0               0                  1   \n",
       "1                0                0               1                  0   \n",
       "2                1                0               1                  0   \n",
       "3                0                1               0                  0   \n",
       "4                0                1               0                  0   \n",
       "\n",
       "   v_score_text_High  v_score_text_Low  v_score_text_Medium  event  target  \\\n",
       "0                  0                 1                    0      1     1.0   \n",
       "1                  0                 1                    0      1     1.0   \n",
       "2                  0                 1                    0      0     0.0   \n",
       "3                  1                 0                    0      1     1.0   \n",
       "4                  1                 0                    0      0     1.0   \n",
       "\n",
       "   pred_relu  pred_tanh  pred_elu  \n",
       "0          1          1         1  \n",
       "1          1          1         1  \n",
       "2          0          0         0  \n",
       "3          1          1         1  \n",
       "4          1          1         1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56a11fb",
   "metadata": {},
   "source": [
    "## Trial 3.4 - Leaky ReLU (COMPAS) <a id=\"leaky\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c12bb62",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d637e9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 1e-05\n",
      "epochs: 150\n",
      "batches: 100\n"
     ]
    }
   ],
   "source": [
    "#alpha = 1e-5 # 0.00001\n",
    "#epochs = 50\n",
    "#batches = 256\n",
    "hidden1 = leaky\n",
    "hidden2 = leaky\n",
    "hidden3 = leaky\n",
    "out_layer = sigmoid\n",
    "print(f\"learning rate: {alpha}\")\n",
    "print(f\"epochs: {epochs}\")\n",
    "print(f\"batches: {batches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07d24f5",
   "metadata": {},
   "source": [
    "#### Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "661fff72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of MLP(\n",
      "  (linear_stack): Sequential(\n",
      "    (0): Linear(in_features=33, out_features=22, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=22, out_features=14, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=14, out_features=9, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Linear(in_features=9, out_features=1, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# instantiate model\n",
    "model = MLP(X.shape[1], hidden1, hidden2, hidden3, out_layer).to(device)\n",
    "\n",
    "# select optimizing function\n",
    "optimizer = adam(model.parameters(), lr=alpha)\n",
    "\n",
    "# select loss function\n",
    "criterion = mse\n",
    "\n",
    "# accuracy metric\n",
    "metric = torchmetrics.functional.accuracy\n",
    "\n",
    "# display model\n",
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321e45bf",
   "metadata": {},
   "source": [
    "#### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5cfcf9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2531914413\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2523242725\n",
      "Epoch 2 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2530167401\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2521587922\n",
      "Epoch 3 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2528381944\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2519911201\n",
      "Epoch 4 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2526576817\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2518205040\n",
      "Epoch 5 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2524733245\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2516428339\n",
      "Epoch 6 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2522877157\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2514602400\n",
      "Epoch 7 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2520974874\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2512701076\n",
      "Epoch 8 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2518987656\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2510720307\n",
      "Epoch 9 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2516956329\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2508646676\n",
      "Epoch 10 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2514751852\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2506485170\n",
      "Epoch 11 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2512475848\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2504194152\n",
      "Epoch 12 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2510150373\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2501757819\n",
      "Epoch 13 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2507680953\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2499204995\n",
      "Epoch 14 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2505185902\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2496488364\n",
      "Epoch 15 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2502497435\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2493593281\n",
      "Epoch 16 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2499651611\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2490531050\n",
      "Epoch 17 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2496619523\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2487349744\n",
      "Epoch 18 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2493284494\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2483974787\n",
      "Epoch 19 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2489717752\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2480486404\n",
      "Epoch 20 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2485926896\n",
      "\tTest error\tAccuracy: 0.3972602785\tLoss: 0.2476794578\n",
      "Epoch 21 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2481756210\n",
      "\tTest error\tAccuracy: 0.4109589159\tLoss: 0.2472955180\n",
      "Epoch 22 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2477301955\n",
      "\tTest error\tAccuracy: 0.4109589159\tLoss: 0.2468938310\n",
      "Epoch 23 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2472649962\n",
      "\tTest error\tAccuracy: 0.4109589159\tLoss: 0.2464741738\n",
      "Epoch 24 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2467794120\n",
      "\tTest error\tAccuracy: 0.4109589159\tLoss: 0.2460358583\n",
      "Epoch 25 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2462880760\n",
      "\tTest error\tAccuracy: 0.4109589159\tLoss: 0.2455840976\n",
      "Epoch 26 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2457960099\n",
      "\tTest error\tAccuracy: 0.4109589159\tLoss: 0.2451206581\n",
      "Epoch 27 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2452812791\n",
      "\tTest error\tAccuracy: 0.4109589159\tLoss: 0.2446412111\n",
      "Epoch 28 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2447434664\n",
      "\tTest error\tAccuracy: 0.4109589159\tLoss: 0.2441485829\n",
      "Epoch 29 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2441982329\n",
      "\tTest error\tAccuracy: 0.4109589159\tLoss: 0.2436485958\n",
      "Epoch 30 / 150\n",
      "\tTraining\tAccuracy: 0.4411764741\tLoss: 0.2436552048\n",
      "\tTest error\tAccuracy: 0.4109589159\tLoss: 0.2431334200\n",
      "Epoch 31 / 150\n",
      "\tTraining\tAccuracy: 0.4705882370\tLoss: 0.2431008667\n",
      "\tTest error\tAccuracy: 0.4246575236\tLoss: 0.2426144105\n",
      "Epoch 32 / 150\n",
      "\tTraining\tAccuracy: 0.4705882370\tLoss: 0.2425436676\n",
      "\tTest error\tAccuracy: 0.4383561611\tLoss: 0.2420902373\n",
      "Epoch 33 / 150\n",
      "\tTraining\tAccuracy: 0.4705882370\tLoss: 0.2419776320\n",
      "\tTest error\tAccuracy: 0.4657534361\tLoss: 0.2415479152\n",
      "Epoch 34 / 150\n",
      "\tTraining\tAccuracy: 0.4705882370\tLoss: 0.2414141893\n",
      "\tTest error\tAccuracy: 0.4931506813\tLoss: 0.2410063815\n",
      "Epoch 35 / 150\n",
      "\tTraining\tAccuracy: 0.4705882370\tLoss: 0.2408411354\n",
      "\tTest error\tAccuracy: 0.5205479264\tLoss: 0.2404519994\n",
      "Epoch 36 / 150\n",
      "\tTraining\tAccuracy: 0.5294117928\tLoss: 0.2402551025\n",
      "\tTest error\tAccuracy: 0.5616438389\tLoss: 0.2398860455\n",
      "Epoch 37 / 150\n",
      "\tTraining\tAccuracy: 0.5294117928\tLoss: 0.2396754920\n",
      "\tTest error\tAccuracy: 0.5890411139\tLoss: 0.2393166600\n",
      "Epoch 38 / 150\n",
      "\tTraining\tAccuracy: 0.5294117928\tLoss: 0.2390768379\n",
      "\tTest error\tAccuracy: 0.6164383292\tLoss: 0.2387321031\n",
      "Epoch 39 / 150\n",
      "\tTraining\tAccuracy: 0.5294117928\tLoss: 0.2384664863\n",
      "\tTest error\tAccuracy: 0.6164383292\tLoss: 0.2381368897\n",
      "Epoch 40 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2378424555\n",
      "\tTest error\tAccuracy: 0.6164383292\tLoss: 0.2375377388\n",
      "Epoch 41 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2371864617\n",
      "\tTest error\tAccuracy: 0.6301369667\tLoss: 0.2369238067\n",
      "Epoch 42 / 150\n",
      "\tTraining\tAccuracy: 0.5882353187\tLoss: 0.2365284860\n",
      "\tTest error\tAccuracy: 0.6438356042\tLoss: 0.2363052716\n",
      "Epoch 43 / 150\n",
      "\tTraining\tAccuracy: 0.6176470518\tLoss: 0.2358259857\n",
      "\tTest error\tAccuracy: 0.6712328792\tLoss: 0.2356652717\n",
      "Epoch 44 / 150\n",
      "\tTraining\tAccuracy: 0.6176470518\tLoss: 0.2351317108\n",
      "\tTest error\tAccuracy: 0.6986301541\tLoss: 0.2350245516\n",
      "Epoch 45 / 150\n",
      "\tTraining\tAccuracy: 0.6176470518\tLoss: 0.2344161868\n",
      "\tTest error\tAccuracy: 0.7123287916\tLoss: 0.2343659287\n",
      "Epoch 46 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2336995453\n",
      "\tTest error\tAccuracy: 0.7123287916\tLoss: 0.2336942284\n",
      "Epoch 47 / 150\n",
      "\tTraining\tAccuracy: 0.6764705777\tLoss: 0.2329781353\n",
      "\tTest error\tAccuracy: 0.7123287916\tLoss: 0.2330097123\n",
      "Epoch 48 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2322409451\n",
      "\tTest error\tAccuracy: 0.7260273695\tLoss: 0.2323161051\n",
      "Epoch 49 / 150\n",
      "\tTraining\tAccuracy: 0.7058823705\tLoss: 0.2314949632\n",
      "\tTest error\tAccuracy: 0.7260273695\tLoss: 0.2316077458\n",
      "Epoch 50 / 150\n",
      "\tTraining\tAccuracy: 0.7352941036\tLoss: 0.2307237685\n",
      "\tTest error\tAccuracy: 0.7260273695\tLoss: 0.2308868546\n",
      "Epoch 51 / 150\n",
      "\tTraining\tAccuracy: 0.7352941036\tLoss: 0.2299404144\n",
      "\tTest error\tAccuracy: 0.7260273695\tLoss: 0.2301567041\n",
      "Epoch 52 / 150\n",
      "\tTraining\tAccuracy: 0.7352941036\tLoss: 0.2291440815\n",
      "\tTest error\tAccuracy: 0.7397260070\tLoss: 0.2294153486\n",
      "Epoch 53 / 150\n",
      "\tTraining\tAccuracy: 0.7352941036\tLoss: 0.2283331305\n",
      "\tTest error\tAccuracy: 0.7534246445\tLoss: 0.2286673217\n",
      "Epoch 54 / 150\n",
      "\tTraining\tAccuracy: 0.7352941036\tLoss: 0.2275088578\n",
      "\tTest error\tAccuracy: 0.7671232820\tLoss: 0.2279089526\n",
      "Epoch 55 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2266740948\n",
      "\tTest error\tAccuracy: 0.7808219194\tLoss: 0.2271360585\n",
      "Epoch 56 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2258377671\n",
      "\tTest error\tAccuracy: 0.7808219194\tLoss: 0.2263528187\n",
      "Epoch 57 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2249822617\n",
      "\tTest error\tAccuracy: 0.7808219194\tLoss: 0.2255595823\n",
      "Epoch 58 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2241057307\n",
      "\tTest error\tAccuracy: 0.7808219194\tLoss: 0.2247552623\n",
      "Epoch 59 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2232242972\n",
      "\tTest error\tAccuracy: 0.7808219194\tLoss: 0.2239455779\n",
      "Epoch 60 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2223243564\n",
      "\tTest error\tAccuracy: 0.7808219194\tLoss: 0.2231197811\n",
      "Epoch 61 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2214161903\n",
      "\tTest error\tAccuracy: 0.7945205569\tLoss: 0.2222793358\n",
      "Epoch 62 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2205067575\n",
      "\tTest error\tAccuracy: 0.7945205569\tLoss: 0.2214374053\n",
      "Epoch 63 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2195900977\n",
      "\tTest error\tAccuracy: 0.7945205569\tLoss: 0.2205887628\n",
      "Epoch 64 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2186537683\n",
      "\tTest error\tAccuracy: 0.7945205569\tLoss: 0.2197216565\n",
      "Epoch 65 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2177171558\n",
      "\tTest error\tAccuracy: 0.8082191944\tLoss: 0.2188509958\n",
      "Epoch 66 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2167726904\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2179662174\n",
      "Epoch 67 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2158425748\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2170789299\n",
      "Epoch 68 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2148903310\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2161814599\n",
      "Epoch 69 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2139265090\n",
      "\tTest error\tAccuracy: 0.8219178319\tLoss: 0.2152777428\n",
      "Epoch 70 / 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2129469216\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.2143624148\n",
      "Epoch 71 / 150\n",
      "\tTraining\tAccuracy: 0.7647058964\tLoss: 0.2119623870\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.2134389366\n",
      "Epoch 72 / 150\n",
      "\tTraining\tAccuracy: 0.7941176295\tLoss: 0.2109721899\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.2125118212\n",
      "Epoch 73 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2099698633\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.2115772806\n",
      "Epoch 74 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2089601457\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.2106316239\n",
      "Epoch 75 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2079326361\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.2096784945\n",
      "Epoch 76 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2069185078\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.2087207919\n",
      "Epoch 77 / 150\n",
      "\tTraining\tAccuracy: 0.8235294223\tLoss: 0.2058893144\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.2077545623\n",
      "Epoch 78 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2048546225\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.2067882270\n",
      "Epoch 79 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2038169205\n",
      "\tTest error\tAccuracy: 0.8356164098\tLoss: 0.2058144091\n",
      "Epoch 80 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2027756423\n",
      "\tTest error\tAccuracy: 0.8493150473\tLoss: 0.2048329236\n",
      "Epoch 81 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2017197311\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.2038500181\n",
      "Epoch 82 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.2006548196\n",
      "\tTest error\tAccuracy: 0.8630136847\tLoss: 0.2028553018\n",
      "Epoch 83 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1995925009\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.2018590300\n",
      "Epoch 84 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1985276788\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.2008584404\n",
      "Epoch 85 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1974468827\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1998446541\n",
      "Epoch 86 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1963797510\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1988310253\n",
      "Epoch 87 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1952845007\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1978330946\n",
      "Epoch 88 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1941795647\n",
      "\tTest error\tAccuracy: 0.8767123222\tLoss: 0.1968107763\n",
      "Epoch 89 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1931008399\n",
      "\tTest error\tAccuracy: 0.9041095972\tLoss: 0.1957987561\n",
      "Epoch 90 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1919878274\n",
      "\tTest error\tAccuracy: 0.9178082347\tLoss: 0.1947725131\n",
      "Epoch 91 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1908741593\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1937479029\n",
      "Epoch 92 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1897443980\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1927346921\n",
      "Epoch 93 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1886183918\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1917007984\n",
      "Epoch 94 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1874889433\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1906629042\n",
      "Epoch 95 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1863528341\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1896259054\n",
      "Epoch 96 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1852058470\n",
      "\tTest error\tAccuracy: 0.9315068722\tLoss: 0.1885850955\n",
      "Epoch 97 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1840650886\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1875366143\n",
      "Epoch 98 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1829135269\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1864867955\n",
      "Epoch 99 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1817879677\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1854336574\n",
      "Epoch 100 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1806336790\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1843802645\n",
      "Epoch 101 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1794988066\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1833062945\n",
      "Epoch 102 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1783559769\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1822671294\n",
      "Epoch 103 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1772152185\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1811989148\n",
      "Epoch 104 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1760834754\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1801405911\n",
      "Epoch 105 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1749593168\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1790779034\n",
      "Epoch 106 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1738041192\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1779994418\n",
      "Epoch 107 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1726800650\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1769410599\n",
      "Epoch 108 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1715403050\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1758602240\n",
      "Epoch 109 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1704264432\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1747972412\n",
      "Epoch 110 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1692983955\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1737052032\n",
      "Epoch 111 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1681443900\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1726466800\n",
      "Epoch 112 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1670285612\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1715771102\n",
      "Epoch 113 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1658813953\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1704905721\n",
      "Epoch 114 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1647649258\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1694168562\n",
      "Epoch 115 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1636176705\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1683266993\n",
      "Epoch 116 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1624925733\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1672564894\n",
      "Epoch 117 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1613446772\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1661602074\n",
      "Epoch 118 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1602010429\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1650684405\n",
      "Epoch 119 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1590805948\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1639954526\n",
      "Epoch 120 / 150\n",
      "\tTraining\tAccuracy: 0.8529411554\tLoss: 0.1579606533\n",
      "\tTest error\tAccuracy: 0.9452054501\tLoss: 0.1629090061\n",
      "Epoch 121 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1568189114\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1618121217\n",
      "Epoch 122 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1556967050\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1607242212\n",
      "Epoch 123 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1545840949\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1596366550\n",
      "Epoch 124 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1534634531\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1585366421\n",
      "Epoch 125 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1523298174\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1574398691\n",
      "Epoch 126 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1512326747\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1563571379\n",
      "Epoch 127 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1501170844\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1552649658\n",
      "Epoch 128 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1490033120\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1541718216\n",
      "Epoch 129 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1478987485\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1530786760\n",
      "Epoch 130 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1467576772\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1519673523\n",
      "Epoch 131 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1456569731\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1508836860\n",
      "Epoch 132 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1445660591\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1498006504\n",
      "Epoch 133 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1434388459\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1486881723\n",
      "Epoch 134 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1423247606\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1476032109\n",
      "Epoch 135 / 150\n",
      "\tTraining\tAccuracy: 0.9117646813\tLoss: 0.1412092149\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1465141383\n",
      "Epoch 136 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1400910765\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1454207290\n",
      "Epoch 137 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1389717460\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1443257460\n",
      "Epoch 138 / 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1378590912\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1432162938\n",
      "Epoch 139 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1367232352\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1421253546\n",
      "Epoch 140 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1356220543\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1410347897\n",
      "Epoch 141 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1345204413\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1399458388\n",
      "Epoch 142 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1334127486\n",
      "\tTest error\tAccuracy: 0.9589040875\tLoss: 0.1388452660\n",
      "Epoch 143 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1323233694\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1377617337\n",
      "Epoch 144 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1312430799\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1366901834\n",
      "Epoch 145 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1301447302\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1355740957\n",
      "Epoch 146 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1290627569\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1344959750\n",
      "Epoch 147 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1279987395\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1334153279\n",
      "Epoch 148 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1269220710\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1323273640\n",
      "Epoch 149 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1258518845\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1312534990\n",
      "Epoch 150 / 150\n",
      "\tTraining\tAccuracy: 0.9411764741\tLoss: 0.1247632205\n",
      "\tTest error\tAccuracy: 0.9726027250\tLoss: 0.1301527570\n",
      "Finished\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * \n",
      "Execution time (in seconds): 19.428118981071748\n"
     ]
    }
   ],
   "source": [
    "training_results = []\n",
    "training_losses = []\n",
    "testing_results = []\n",
    "\n",
    "training_results, training_losses, testing_results = evaluate(training_s,\n",
    "                                                             test_s,\n",
    "                                                             model,\n",
    "                                                             loss_function,\n",
    "                                                             metric,\n",
    "                                                             optimizer,\n",
    "                                                             epochs,\n",
    "                                                             early_stop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3026827f",
   "metadata": {},
   "source": [
    "#### Prepare Leaky ReLU data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b33e2a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "tailend = f\"Leaky ReLU ({prefix})\"\n",
    "\n",
    "train_preds, test_preds = prep(tailend, training_results, testing_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f2436d",
   "metadata": {},
   "source": [
    "#### Add Leaky ReLU data to persistent storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ccb2f905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compas_leaky_mk2.pth has been saved.\n"
     ]
    }
   ],
   "source": [
    "df[\"pred_leaky\"] = np.array(np.round(test_preds[-1])).astype(int)\n",
    "name = f\"{prefix}_leaky_{suffix}.pth\"\n",
    "custom_save(name, model,1)\n",
    "# torch.save(model, \"loans_leaky_scaled.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "baa26181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat_25to45</th>\n",
       "      <th>age_cat_over45</th>\n",
       "      <th>age_cat_under25</th>\n",
       "      <th>race_black</th>\n",
       "      <th>race_asian</th>\n",
       "      <th>race_white</th>\n",
       "      <th>race_hispanic</th>\n",
       "      <th>race_native</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>score_text_High</th>\n",
       "      <th>score_text_Low</th>\n",
       "      <th>score_text_Medium</th>\n",
       "      <th>v_score_text_High</th>\n",
       "      <th>v_score_text_Low</th>\n",
       "      <th>v_score_text_Medium</th>\n",
       "      <th>event</th>\n",
       "      <th>target</th>\n",
       "      <th>pred_relu</th>\n",
       "      <th>pred_tanh</th>\n",
       "      <th>pred_elu</th>\n",
       "      <th>pred_leaky</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1171</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  juv_fel_count  decile_score  juv_misd_count  juv_other_count  \\\n",
       "0   25              0             5               0                1   \n",
       "1   35              0             4               0                0   \n",
       "2   32              0             4               0                0   \n",
       "3   20              0            10               0                0   \n",
       "4   50              0             8               0                2   \n",
       "\n",
       "   priors_count  days_b_screening_arrest  c_days_from_compas  is_recid  \\\n",
       "0             4                       -1                   1         1   \n",
       "1             3                       -1                   0         1   \n",
       "2             1                        0                   0         0   \n",
       "3             0                       -1                   1         1   \n",
       "4            24                        0                   1         1   \n",
       "\n",
       "   is_violent_recid  decile_score.1  v_decile_score  priors_count.1  start  \\\n",
       "0                 0               5               4               4     32   \n",
       "1                 0               4               4               3      9   \n",
       "2                 0               4               3               1      0   \n",
       "3                 1              10              10               0      3   \n",
       "4                 1               8               8              24     32   \n",
       "\n",
       "    end  sex  age_cat_25to45  age_cat_over45  age_cat_under25  race_black  \\\n",
       "0   304    0               1               0                0           1   \n",
       "1   462    0               1               0                0           0   \n",
       "2  1171    0               1               0                0           1   \n",
       "3    20    0               0               0                1           1   \n",
       "4    87    0               0               1                0           1   \n",
       "\n",
       "   race_asian  race_white  race_hispanic  race_native  race_Other  \\\n",
       "0           0           0              0            0           0   \n",
       "1           0           1              0            0           0   \n",
       "2           0           0              0            0           0   \n",
       "3           0           0              0            0           0   \n",
       "4           0           0              0            0           0   \n",
       "\n",
       "   c_charge_degree  score_text_High  score_text_Low  score_text_Medium  \\\n",
       "0                1                0               0                  1   \n",
       "1                0                0               1                  0   \n",
       "2                1                0               1                  0   \n",
       "3                0                1               0                  0   \n",
       "4                0                1               0                  0   \n",
       "\n",
       "   v_score_text_High  v_score_text_Low  v_score_text_Medium  event  target  \\\n",
       "0                  0                 1                    0      1     1.0   \n",
       "1                  0                 1                    0      1     1.0   \n",
       "2                  0                 1                    0      0     0.0   \n",
       "3                  1                 0                    0      1     1.0   \n",
       "4                  1                 0                    0      0     1.0   \n",
       "\n",
       "   pred_relu  pred_tanh  pred_elu  pred_leaky  \n",
       "0          1          1         1           1  \n",
       "1          1          1         1           1  \n",
       "2          0          0         0           0  \n",
       "3          1          1         1           1  \n",
       "4          1          1         1           1  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1422aae",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cecbae",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c83d1d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compas_results_mk2.parquet has been saved.\n"
     ]
    }
   ],
   "source": [
    "name = f\"{prefix}_results_{suffix}.parquet\"\n",
    "custom_save(name, df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09301c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
